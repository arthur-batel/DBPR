{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# IMPACT experiments\n",
    "### 1. Init\n",
    "#### 1.1. Import libraries"
   ],
   "id": "bc0774a07482a44f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T14:34:16.991210Z",
     "start_time": "2025-02-14T14:34:15.876857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from IMPACT import utils\n",
    "utils.set_seed(0)\n",
    "from IMPACT import dataset\n",
    "from IMPACT import model\n",
    "import optuna\n",
    "import logging\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from importlib import reload"
   ],
   "id": "30c2bf011793765d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "CUDA is not available. Skipping CUDA seed setting.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2. Start tensorboard",
   "id": "6f4d550fa43938b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorboard import notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --reuse=False --logdir /home/arthurb/Programmation/liriscat/experiments/tensorboard --load_fast=false --reload_interval=1 \n",
    "\n",
    "print(notebook.list())\n",
    "# access tensorboard at : http://localhost:6006"
   ],
   "id": "db4f414458219d16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3. Set up the loggers",
   "id": "18c248901436fb79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "utils.setuplogger(verbose = True, log_name=\"IMPACT_postcovid\")",
   "id": "f544e590b910dcad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.5. Parametrize the datasets",
   "id": "61158521634c09ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# choose dataset here\n",
    "dataset_name = 'postcovid'\n",
    "version= \"\"#\"_small\"\n",
    "# modify config here\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "config = {\n",
    "    \n",
    "    # General params\n",
    "    'seed' : 0,\n",
    "    \n",
    "    # Saving params\n",
    "    'load_params': False,\n",
    "    'save_params': False,\n",
    "    'embs_path' : '../embs/'+str(dataset_name),\n",
    "    'params_path' :'../ckpt/'+str(dataset_name),\n",
    "    \n",
    "    # training mode\n",
    "    'early_stopping' : True, \n",
    "    'fast_training' : True, # (Only taken in account if early_stopping == true) If true, doesn't compute valid rmse PC-ER\n",
    "    \n",
    "    # Learning params\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 2048,\n",
    "    'num_epochs': 200,\n",
    "    'num_dim': 10,\n",
    "    'eval_freq' : 1,\n",
    "    'patience' : 30,\n",
    "    'device': device,\n",
    "    'lambda' : 7.7e-6,\n",
    "    'tensorboard': False,\n",
    "    'flush_freq' : True,\n",
    "\n",
    "    # Testing params\n",
    "    'test_batch_size' : 10000,\n",
    "    \n",
    "    # for NeuralCD\n",
    "    'prednet_len1': 128,\n",
    "    'prednet_len2': 64,\n",
    "    'best_params_path':'',\n",
    "    \n",
    "    #For GCCD\n",
    "    'num_layers': 0,\n",
    "    'version': 'pair',\n",
    "    'p_dropout': 0,\n",
    "    'low_mem_mode' : True,\n",
    "    'user_nbrs_n' : 10,\n",
    "    'item_nbrs_n' : 5\n",
    "}\n",
    "concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "utils.set_seed(config['seed'])\n",
    "dataset_name += version\n",
    "logging.info(f'#### {dataset_name} ####')\n",
    "logging.info(f'#### config : {config} ####')"
   ],
   "id": "c4664f14b5fe9ad1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. CDM Hyperparameter search",
   "id": "2eecb5813a4dcd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1. Sequential",
   "id": "7f8a6aadbcd3a357"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "\n",
    "\n",
    "seed = 0\n",
    "utils.set_seed(0)\n",
    "\n",
    "config['seed'] = seed\n",
    "config['early_stopping'] = True\n",
    "config['esc'] = 'error'#'objectives' #'loss' 'delta_objectives'\n",
    "config['num_epochs']=200\n",
    "config['eval_freq']=1\n",
    "config['patience']=30\n",
    "\n",
    "config['verbose_early_stopping'] = False\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['save_params']= False\n",
    "config['disable_tqdm'] = True\n",
    "\n",
    "\n",
    "    \n",
    "def load_dataset(dataset_name : str) :\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # read datasets\n",
    "    i_fold = 0\n",
    "    concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "    concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "    metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "    train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                             encoding='utf-8').to_records(index=False,\n",
    "                                                          column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                         \"correct\": float,\"dimension_id\":int})\n",
    "    valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "    \n",
    "    train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "    \n",
    "    return train_data,valid_data,concept_map,metadata\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 5e-2, log=True)\n",
    "    lambda_param = trial.suggest_float('lambda', 1e-7, 5e-4, log=True)\n",
    "    d_in =  trial.suggest_int('d_in', 3,5)\n",
    "    num_responses = trial.suggest_int('num_responses', 9,13)\n",
    "    \n",
    "    config['learning_rate'] = lr\n",
    "    config['lambda'] = lambda_param\n",
    "    config['d_in'] =d_in\n",
    "    config['num_responses'] =num_responses\n",
    "    \n",
    "    algo = model.IMPACT(**config)\n",
    "        \n",
    "    # Init model\n",
    "    algo.init_model(train_data, valid_data)\n",
    "\n",
    "    # train model ----\n",
    "    algo.train(train_data, valid_data)\n",
    "    \n",
    "    best_valid_rmse = algo.best_valid_rmse\n",
    "    \n",
    "    logging.info(\"-------Trial number : \"+str(trial.number)+\"\\nBest epoch : \"+str(algo.best_epoch)+\"\\nValues : [\"+str(best_valid_rmse)+\"]\\nParams : \"+str(trial.params))\n",
    "    \n",
    "    del algo.model\n",
    "    del algo   \n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "                \n",
    "    return best_valid_rmse"
   ],
   "id": "53c3976f69491bab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_name = \"postcovid\"\n",
    "logging.info(dataset_name)\n",
    "train_data,valid_data,concept_map,metadata = load_dataset(dataset_name)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    directions=[\"minimize\"],  # Specify directions for each objective\n",
    ")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "study.optimize(objective, n_trials=2, n_jobs=1, gc_after_trial=True)\n",
    "\n",
    "# Analyze the results\n",
    "## requirements : plotly, nbformat\n",
    "pareto_trials = study.best_trials\n",
    "\n",
    "logging.info(f\"Best trial for {dataset_name} : {study.best_trials}\")\n",
    "for trial in pareto_trials:\n",
    "    logging.info(f\"Trial #{trial.number}\")\n",
    "    logging.info(f\"  RMSE: {trial.values}\")\n",
    "    #logging.info(f\"  DOA: {trial.values[1]}\")\n",
    "    logging.info(f\"  Params: {trial.params}\")"
   ],
   "id": "b7f525cc9a1b247f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2. Parallelized",
   "id": "62dd8fde44ffb96d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#ipcluster start --n=3\n",
    "#ipcluster stop\n",
    "\n",
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "from ipyparallel import Client\n",
    "import dill\n",
    "\n",
    "cat_absolute_path = os.path.abspath('../../')\n",
    "\n",
    "rc = Client()\n",
    "rc[:].use_dill()\n",
    "lview = rc.load_balanced_view()\n",
    "\n",
    "\n",
    "rc[:].execute(\"import sys; sys.path.append('\"+cat_absolute_path+\"')\")\n",
    "print(\"sys.path.append(\"+cat_absolute_path+\")\")\n",
    "with rc[:].sync_imports():\n",
    "    import json\n",
    "    from IMPACT import utils, model, dataset\n",
    "    import logging\n",
    "    import gc\n",
    "    import torch\n",
    "\n",
    "seed = 0\n",
    "utils.set_seed(0)\n",
    "\n",
    "config['seed'] = seed\n",
    "config['early_stopping'] = True\n",
    "config['esc'] = 'error'#'objectives' #'loss' 'delta_objectives'\n",
    "config['num_epochs']=200\n",
    "config['eval_freq']=1\n",
    "config['patience']=30\n",
    "\n",
    "config['verbose_early_stopping'] = False\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['save_params']= False\n",
    "config['disable_tqdm'] = True\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(dataset_name : str) :\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # read datasets\n",
    "    i_fold = 0\n",
    "    concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "    concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "    metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "    train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                             encoding='utf-8').to_records(index=False,\n",
    "                                                          column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                         \"correct\": float,\"dimension_id\":int})\n",
    "    valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "\n",
    "    train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "\n",
    "    return train_data,valid_data,concept_map,metadata\n",
    "\n",
    "def launch_test(trial,train_data,valid_data,config) :\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    algo = model.IMPACT(**config)\n",
    "\n",
    "    # Init model\n",
    "    algo.init_model(train_data, valid_data)\n",
    "\n",
    "    # train model ----\n",
    "    algo.train(train_data, valid_data)\n",
    "\n",
    "    best_valid_rmse = algo.best_valid_rmse\n",
    "\n",
    "    logging.info(\"-------Trial number : \"+str(trial.number)+\"\\nBest epoch : \"+str(algo.best_epoch)+\"\\nValues : [\"+str(best_valid_rmse)+\"]\\nParams : \"+str(trial.params))\n",
    "\n",
    "    del algo.model\n",
    "    del algo\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return best_valid_rmse\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    lr = trial.suggest_float('learning_rate', 0.001, 0.01, log=True)\n",
    "    lambda_param = trial.suggest_float('lambda', 1.2e-6, 1.6e-6, log=True)\n",
    "    d_in =  trial.suggest_int('d_in', 5,7)\n",
    "    num_responses = trial.suggest_int('num_responses', 11,13)\n",
    "\n",
    "    config['learning_rate'] = lr\n",
    "    config['lambda'] = lambda_param\n",
    "    config['d_in'] =d_in\n",
    "    config['num_responses'] =num_responses\n",
    "\n",
    "    return lview.apply_async(launch_test,trial,train_data,valid_data, config).get()\n",
    "\n"
   ],
   "id": "1c938ca9da1d7b10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "dataset_name = \"movielens\"\n",
    "logging.info(dataset_name)\n",
    "train_data,valid_data,concept_map,metadata = load_dataset(dataset_name)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    directions=[\"minimize\"],  # Specify directions for each objective\n",
    ")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "study.optimize(objective, n_trials=100, n_jobs=3, gc_after_trial=True)\n",
    "\n",
    "# Analyze the results\n",
    "## requirements : plotly, nbformat\n",
    "pareto_trials = study.best_trials\n",
    "\n",
    "logging.info(f\"Best trial for {dataset_name} : {study.best_trials}\")\n",
    "for trial in pareto_trials:\n",
    "    logging.info(f\"Trial #{trial.number}\")\n",
    "    logging.info(f\"  RMSE: {trial.values}\")\n",
    "    #logging.info(f\"  DOA: {trial.values[1]}\")\n",
    "    logging.info(f\"  Params: {trial.params}\")"
   ],
   "id": "2903754279c264b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.3. Number of parameters computation",
   "id": "da61a9e00a0211e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "d_in=5\n",
    "num_responses=13\n",
    "metadata['num_item_id']*num_responses*d_in+metadata['num_user_id']*metadata['num_dimension_id']+metadata['num_dimension_id']*metadata['num_dimension_id']*d_in"
   ],
   "id": "c1ba9c0a898796ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. CDM Prediction\n",
    "#### 3.1. Parallel training and testing"
   ],
   "id": "6d574559bd418d77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#ipcluster start --n=4\n",
    "#ipcluster stop"
   ],
   "id": "303c944f807c2383",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from ipyparallel import Client\n",
    "from IMPACT import utils\n",
    "import dill\n",
    "\n",
    "cat_absolute_path = os.path.abspath('../../')\n",
    "\n",
    "rc = Client()\n",
    "rc[:].use_dill()\n",
    "lview = rc.load_balanced_view()\n",
    "\n",
    "# Synchronize imports with all engines:\n",
    "rc[:].execute(\"import sys; sys.path.append('\"+cat_absolute_path+\"')\")\n",
    "rc[:].execute(\"import os; os.chdir('./liriscat/experiments/notebook_examples')\")\n",
    "\n",
    "with rc[:].sync_imports():\n",
    "    from IMPACT import utils, model, dataset\n",
    "\n",
    "config[\"disable_tqdm\"] = True\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['early_stopping'] = True\n",
    "config['save_params']=True # Save all model parameters and save an array of the embeddings\n",
    "config['verbose_early_stopping'] = False\n",
    "config['esc'] = 'error'\n",
    "\n",
    "def launch_training(seed:int,config:dict,train_data,valid_data,test_data,test_dataloader, concept_map) :\n",
    "    utils.set_seed(seed)\n",
    "    config['seed'] = seed\n",
    "\n",
    "    algo = model.IMPACT(**config)\n",
    "\n",
    "    # Init model\n",
    "    algo.init_model(train_data, valid_data)\n",
    "\n",
    "    # train model ----\n",
    "    algo.train(train_data, valid_data)\n",
    "\n",
    "    emb = algo.model.users_emb.weight.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"r2\":[], \"pc-er\" : []}\n",
    "\n",
    "    metrics[\"pc-er\"].append(algo.evaluate_emb(test_data,concept_map)['pc-er'])\n",
    "    eval = algo.evaluate_test(test_dataloader)\n",
    "    metrics[\"rmse\"].append(eval[\"rmse\"].numpy().tolist())\n",
    "    metrics[\"mae\"].append(eval[\"mae\"].numpy().tolist())\n",
    "    metrics[\"r2\"].append(eval[\"r2\"].numpy().tolist())\n",
    "\n",
    "    return (metrics,emb)\n",
    "\n",
    "def fold_test(i_fold : int, dataset_name:str, config : dict) :\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Dataset downloading for doa and rm\n",
    "    warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "    concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "    metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "    concept_array, concept_lens=utils.preprocess_concept_map(concept_map)\n",
    "\n",
    "    # read datasets\n",
    "    train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "    valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "    test_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_test_quadruples_vert_{i_fold}.csv',\n",
    "                                encoding='utf-8').to_records(index=False,\n",
    "                                                             column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                            \"correct\": float,\"dimension_id\":int})\n",
    "\n",
    "    train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "    test_data = dataset.LoaderDataset(test_quadruplets, concept_map, metadata)\n",
    "    test_dataloader = data.DataLoader(test_data, batch_size=config['test_batch_size'], shuffle=False)\n",
    "\n",
    "    seeds_combinations = []\n",
    "    for seed in range(3) :\n",
    "        seeds_combinations.append((seed,lview.apply_async(launch_training,seed,config,train_data,valid_data,test_data,test_dataloader, concept_map)))\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"r2\":[], \"pc-er\" : [], \"doa\": [], 'rm' : []}\n",
    "\n",
    "    for seed,async_result in seeds_combinations:\n",
    "        metric, emb = async_result.get()\n",
    "        # test model ----\n",
    "        logging.info(f\"Test done - seed : {seed}, i_fold : {i_fold}\")\n",
    "        for k in metric.keys():\n",
    "            metrics[k].extend(metric[k])\n",
    "\n",
    "        metrics[\"doa\"].append(np.mean(utils.evaluate_doa(emb,test_data.log_tensor.cpu().numpy(),metadata,concept_map)))\n",
    "        metrics[\"rm\"].append(np.mean(utils.compute_rm_fold(emb,test_quadruplets, concept_array, concept_lens)))\n",
    "        pd.DataFrame(emb).to_csv(\"../embs/\"+dataset_name+\"_IMPACT_cornac_Iter_fold\"+str(i_fold)+\"_seed_\"+str(seed)+\".csv\",index=False,header=False)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test(dataset_name:str, config : dict) :\n",
    "\n",
    "    logging.info(f'#### {dataset_name} ####')\n",
    "    logging.info(f'#### config : {config} ####')\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"r2\":[], \"pc-er\" : [], \"doa\": [], 'rm' : []}\n",
    "\n",
    "    fold_combinations = []\n",
    "    for i_fold in range(5):\n",
    "        fold_combinations.append(fold_test(i_fold,dataset_name, config))\n",
    "\n",
    "    for metric in fold_combinations:\n",
    "        for k in metrics.keys():\n",
    "            metrics[k].extend(metric[k])\n",
    "\n",
    "    df = pd.DataFrame(metrics)\n",
    "    logging.info('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(), df['rmse'].std()))\n",
    "    logging.info('mae : {:.4f} +- {:.4f}'.format(df['mae'].mean(), df['mae'].std()))\n",
    "    logging.info('r2 : {:.4f} +- {:.4f}'.format(df['r2'].mean(), df['r2'].std()))\n",
    "    logging.info('pc-er : {:.4f} +- {:.4f}'.format(df['pc-er'].mean(), df['pc-er'].std()))\n",
    "    logging.info('doa : {:.4f} +- {:.4f}'.format(df['doa'].mean(), df['doa'].std()))\n",
    "    logging.info('rm : {:.4f} +- {:.4f}'.format(df['rm'].mean(), df['rm'].std()))\n",
    "\n",
    "    return metrics"
   ],
   "id": "d8a30ea4ddf5e7b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "dataset_name = \"postcovid\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"movielens\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02515\n",
    "config['lambda'] = 2e-7\n",
    "config['d_in'] = 10\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"portrait\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.04568\n",
    "config['lambda'] = 2e-7\n",
    "config['d_in'] = 6\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"promis\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.01227\n",
    "config['lambda'] = 1e-7\n",
    "config['d_in'] = 6\n",
    "config['num_responses'] = 13\n",
    "metrics = test(dataset_name,config)"
   ],
   "id": "d2aff2fe42621c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.2. Sequential training and testing",
   "id": "f79e6c9c01a718e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "\n",
    "config[\"disable_tqdm\"] = True\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['early_stopping'] = True\n",
    "config['save_params']=False # Save all model parameters and save an array of the embeddings\n",
    "config['num_epochs']=200\n",
    "config['verbose_early_stopping'] = False\n",
    "config['esc'] = 'error'\n",
    "\n",
    "def test(dataset_name:str, config : dict) :\n",
    "\n",
    "    logging.info(f'#### {dataset_name} ####')\n",
    "    logging.info(f'#### config : {config} ####')\n",
    "    config['embs_path']='../embs/'+str(dataset_name)\n",
    "    config['params_path']='../ckpt/'+str(dataset_name)\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"r2\":[], \"pc-er\" : [], \"doa\": [], 'rm' : []}\n",
    "\n",
    "    for i_fold in range(1):\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Dataset downloading for doa and rm\n",
    "        warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "        concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "        concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "        metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "        concept_array, concept_lens=utils.preprocess_concept_map(concept_map)\n",
    "\n",
    "        # read datasets\n",
    "        train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                                     encoding='utf-8').to_records(index=False,\n",
    "                                                                  column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                                 \"correct\": float,\"dimension_id\":int})\n",
    "        valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                     encoding='utf-8').to_records(index=False,\n",
    "                                                                  column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                                 \"correct\": float,\"dimension_id\":int})\n",
    "        test_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_test_quadruples_vert_{i_fold}.csv',\n",
    "                                    encoding='utf-8').to_records(index=False,\n",
    "                                                                 column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                                \"correct\": float,\"dimension_id\":int})\n",
    "\n",
    "        train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "        valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "        test_data = dataset.LoaderDataset(test_quadruplets, concept_map, metadata)\n",
    "        test_dataloader = data.DataLoader(test_data, batch_size=config['test_batch_size'], shuffle=False)\n",
    "\n",
    "        for seed in range(2):\n",
    "    \n",
    "            # Set the seed\n",
    "            utils.set_seed(seed)\n",
    "            config['seed'] = seed\n",
    "\n",
    "            algo = model.IMPACT(**config)\n",
    "\n",
    "            # Init model\n",
    "            algo.init_model(train_data, valid_data)\n",
    "\n",
    "            # train model ----\n",
    "            algo.train(train_data, valid_data)\n",
    "\n",
    "            # test model ----\n",
    "             # test model ----\n",
    "            metrics[\"pc-er\"].append(algo.evaluate_emb(test_data,concept_map)['pc-er'])\n",
    "            eval = algo.evaluate_test(test_dataloader)\n",
    "            metrics[\"rmse\"].append(eval[\"rmse\"].numpy())\n",
    "            metrics[\"mae\"].append(eval[\"mae\"].numpy())\n",
    "            metrics[\"r2\"].append(eval[\"r2\"].numpy())\n",
    "            emb = algo.model.users_emb.weight.detach().cpu().numpy()\n",
    "            metrics[\"doa\"].append(np.mean(utils.evaluate_doa(emb,test_data.log_tensor.cpu().numpy(),metadata,concept_map)))\n",
    "            metrics[\"rm\"].append(np.mean(utils.compute_rm_fold(emb,test_quadruplets, concept_array, concept_lens)))\n",
    "\n",
    "            pd.DataFrame(emb).to_csv(\"../embs/\"+dataset_name+\"_IMPACT_cornac_Iter_fold\"+str(i_fold)+\"_seed_\"+str(seed)+\".csv\",index=False,header=False)\n",
    "\n",
    "    df = pd.DataFrame(metrics)\n",
    "    logging.info('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(), df['rmse'].std()))\n",
    "    logging.info('mae : {:.4f} +- {:.4f}'.format(df['mae'].mean(), df['mae'].std()))\n",
    "    logging.info('r2 : {:.4f} +- {:.4f}'.format(df['r2'].mean(), df['r2'].std()))\n",
    "    logging.info('pc-er : {:.4f} +- {:.4f}'.format(df['pc-er'].mean(), df['pc-er'].std()))\n",
    "    logging.info('doa : {:.4f} +- {:.4f}'.format(df['doa'].mean(), df['doa'].std()))\n",
    "    logging.info('rm : {:.4f} +- {:.4f}'.format(df['rm'].mean(), df['rm'].std()))\n",
    "\n",
    "    return metrics"
   ],
   "id": "59be7fecafcada09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "dataset_name = \"assist0910\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)"
   ],
   "id": "e2e5609a04d6a0d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "dataset_name = \"postcovid\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"movielens\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02515\n",
    "config['lambda'] = 2e-7\n",
    "config['d_in'] = 10\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"portrait\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.04568\n",
    "config['lambda'] = 2e-7\n",
    "config['d_in'] = 6\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"promis\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.01227\n",
    "config['lambda'] = 1e-7\n",
    "config['d_in'] = 6\n",
    "config['num_responses'] = 13\n",
    "metrics = test(dataset_name,config)"
   ],
   "id": "17019087789d375a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
