{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0774a07482a44f",
   "metadata": {},
   "source": [
    "# IMPACT experiments\n",
    "### 1. Init\n",
    "#### 1.1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2bf011793765d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T14:34:16.991210Z",
     "start_time": "2025-02-14T14:34:15.876857Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from IMPACT import utils\n",
    "utils.set_seed(0)\n",
    "from IMPACT import dataset\n",
    "from IMPACT import model\n",
    "import optuna\n",
    "import logging\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d550fa43938b4",
   "metadata": {},
   "source": [
    "#### 1.2. Start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f414458219d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --reuse=False --logdir /home/arthurb/Programmation/liriscat/experiments/tensorboard --load_fast=false --reload_interval=1 \n",
    "\n",
    "print(notebook.list())\n",
    "# access tensorboard at : http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c248901436fb79",
   "metadata": {},
   "source": [
    "#### 1.3. Set up the loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544e590b910dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.setuplogger(verbose = True, log_name=\"IMPACT_postcovid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61158521634c09ce",
   "metadata": {},
   "source": [
    "#### 1.5. Parametrize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4664f14b5fe9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose dataset here\n",
    "dataset_name = 'postcovid'\n",
    "version= \"\"#\"_small\"\n",
    "# modify config here\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "config = {\n",
    "    \n",
    "    # General params\n",
    "    'seed' : 0,\n",
    "    \n",
    "    # Saving params\n",
    "    'load_params': False,\n",
    "    'save_params': False,\n",
    "    'embs_path' : '../embs/'+str(dataset_name),\n",
    "    'params_path' :'../ckpt/'+str(dataset_name),\n",
    "    \n",
    "    # training mode\n",
    "    'early_stopping' : True, \n",
    "    'fast_training' : True, # (Only taken in account if early_stopping == true) If true, doesn't compute valid rmse PC-ER\n",
    "    \n",
    "    # Learning params\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 2048,\n",
    "    'num_epochs': 200,\n",
    "    'num_dim': 10,\n",
    "    'eval_freq' : 1,\n",
    "    'patience' : 30,\n",
    "    'device': device,\n",
    "    'lambda' : 7.7e-6,\n",
    "    'tensorboard': False,\n",
    "    'flush_freq' : True,\n",
    "    \n",
    "    #For IMPACT\n",
    "    'valid_metric' : 'ma_acc'\n",
    "}\n",
    "concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "utils.set_seed(config['seed'])\n",
    "dataset_name += version\n",
    "logging.info(f'#### {dataset_name} ####')\n",
    "logging.info(f'#### config : {config} ####')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eecb5813a4dcd9",
   "metadata": {},
   "source": [
    "### 2. CDM Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a6aadbcd3a357",
   "metadata": {},
   "source": [
    "#### 2.1. Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3976f69491bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "\n",
    "\n",
    "seed = 0\n",
    "utils.set_seed(0)\n",
    "\n",
    "config['seed'] = seed\n",
    "config['early_stopping'] = True\n",
    "config['esc'] = 'error'#'objectives' #'loss' 'delta_objectives'\n",
    "config['num_epochs']=200\n",
    "config['eval_freq']=1\n",
    "config['patience']=30\n",
    "\n",
    "config['verbose_early_stopping'] = False\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['save_params']= False\n",
    "config['disable_tqdm'] = True\n",
    "\n",
    "\n",
    "    \n",
    "def load_dataset(dataset_name : str) :\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # read datasets\n",
    "    i_fold = 0\n",
    "    concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "    concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "    metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "    train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                             encoding='utf-8').to_records(index=False,\n",
    "                                                          column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                         \"correct\": float,\"dimension_id\":int})\n",
    "    valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "    \n",
    "    train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "    \n",
    "    return train_data,valid_data,concept_map,metadata\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 5e-2, log=True)\n",
    "    lambda_param = trial.suggest_float('lambda', 1e-7, 5e-4, log=True)\n",
    "    d_in =  trial.suggest_int('d_in', 3,5)\n",
    "    num_responses = trial.suggest_int('num_responses', 9,13)\n",
    "    \n",
    "    config['learning_rate'] = lr\n",
    "    config['lambda'] = lambda_param\n",
    "    config['d_in'] =d_in\n",
    "    config['num_responses'] =num_responses\n",
    "    \n",
    "    algo = model.IMPACT(**config)\n",
    "        \n",
    "    # Init model\n",
    "    algo.init_model(train_data, valid_data)\n",
    "\n",
    "    # train model ----\n",
    "    algo.train(train_data, valid_data)\n",
    "    \n",
    "    best_valid_rmse = algo.best_valid_rmse\n",
    "    \n",
    "    logging.info(\"-------Trial number : \"+str(trial.number)+\"\\nBest epoch : \"+str(algo.best_epoch)+\"\\nValues : [\"+str(best_valid_rmse)+\"]\\nParams : \"+str(trial.params))\n",
    "    \n",
    "    del algo.model\n",
    "    del algo   \n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "                \n",
    "    return best_valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f525cc9a1b247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"postcovid\"\n",
    "logging.info(dataset_name)\n",
    "train_data,valid_data,concept_map,metadata = load_dataset(dataset_name)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    directions=[\"minimize\"],  # Specify directions for each objective\n",
    ")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "study.optimize(objective, n_trials=2, n_jobs=1, gc_after_trial=True)\n",
    "\n",
    "# Analyze the results\n",
    "## requirements : plotly, nbformat\n",
    "pareto_trials = study.best_trials\n",
    "\n",
    "logging.info(f\"Best trial for {dataset_name} : {study.best_trials}\")\n",
    "for trial in pareto_trials:\n",
    "    logging.info(f\"Trial #{trial.number}\")\n",
    "    logging.info(f\"  RMSE: {trial.values}\")\n",
    "    #logging.info(f\"  DOA: {trial.values[1]}\")\n",
    "    logging.info(f\"  Params: {trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd8fde44ffb96d",
   "metadata": {},
   "source": [
    "#### 2.2. Parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c938ca9da1d7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipcluster start --n=3\n",
    "#ipcluster stop\n",
    "\n",
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "from ipyparallel import Client\n",
    "import dill\n",
    "\n",
    "cat_absolute_path = os.path.abspath('../../')\n",
    "\n",
    "rc = Client()\n",
    "rc[:].use_dill()\n",
    "lview = rc.load_balanced_view()\n",
    "\n",
    "\n",
    "rc[:].execute(\"import sys; sys.path.append('\"+cat_absolute_path+\"')\")\n",
    "print(\"sys.path.append(\"+cat_absolute_path+\")\")\n",
    "with rc[:].sync_imports():\n",
    "    import json\n",
    "    from IMPACT import utils, model, dataset\n",
    "    import logging\n",
    "    import gc\n",
    "    import torch\n",
    "\n",
    "seed = 0\n",
    "utils.set_seed(0)\n",
    "\n",
    "config['seed'] = seed\n",
    "config['early_stopping'] = True\n",
    "config['esc'] = 'error'#'objectives' #'loss' 'delta_objectives'\n",
    "config['num_epochs']=200\n",
    "config['eval_freq']=1\n",
    "config['patience']=30\n",
    "\n",
    "config['verbose_early_stopping'] = False\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['save_params']= False\n",
    "config['disable_tqdm'] = True\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(dataset_name : str) :\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # read datasets\n",
    "    i_fold = 0\n",
    "    concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "    concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "    metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "    train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                             encoding='utf-8').to_records(index=False,\n",
    "                                                          column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                         \"correct\": float,\"dimension_id\":int})\n",
    "    valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "\n",
    "    train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "\n",
    "    return train_data,valid_data,concept_map,metadata\n",
    "\n",
    "def launch_test(trial,train_data,valid_data,config) :\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    algo = model.IMPACT(**config)\n",
    "\n",
    "    # Init model\n",
    "    algo.init_model(train_data, valid_data)\n",
    "\n",
    "    # train model ----\n",
    "    algo.train(train_data, valid_data)\n",
    "\n",
    "    best_valid_rmse = algo.best_valid_rmse\n",
    "\n",
    "    logging.info(\"-------Trial number : \"+str(trial.number)+\"\\nBest epoch : \"+str(algo.best_epoch)+\"\\nValues : [\"+str(best_valid_rmse)+\"]\\nParams : \"+str(trial.params))\n",
    "\n",
    "    del algo.model\n",
    "    del algo\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return best_valid_rmse\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    lr = trial.suggest_float('learning_rate', 0.001, 0.01, log=True)\n",
    "    lambda_param = trial.suggest_float('lambda', 1.2e-6, 1.6e-6, log=True)\n",
    "    d_in =  trial.suggest_int('d_in', 5,7)\n",
    "    num_responses = trial.suggest_int('num_responses', 11,13)\n",
    "\n",
    "    config['learning_rate'] = lr\n",
    "    config['lambda'] = lambda_param\n",
    "    config['d_in'] =d_in\n",
    "    config['num_responses'] =num_responses\n",
    "\n",
    "    return lview.apply_async(launch_test,trial,train_data,valid_data, config).get()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903754279c264b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_name = \"movielens\"\n",
    "logging.info(dataset_name)\n",
    "train_data,valid_data,concept_map,metadata = load_dataset(dataset_name)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    directions=[\"minimize\"],  # Specify directions for each objective\n",
    ")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "study.optimize(objective, n_trials=100, n_jobs=3, gc_after_trial=True)\n",
    "\n",
    "# Analyze the results\n",
    "## requirements : plotly, nbformat\n",
    "pareto_trials = study.best_trials\n",
    "\n",
    "logging.info(f\"Best trial for {dataset_name} : {study.best_trials}\")\n",
    "for trial in pareto_trials:\n",
    "    logging.info(f\"Trial #{trial.number}\")\n",
    "    logging.info(f\"  RMSE: {trial.values}\")\n",
    "    #logging.info(f\"  DOA: {trial.values[1]}\")\n",
    "    logging.info(f\"  Params: {trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da61a9e00a0211e",
   "metadata": {},
   "source": [
    "#### 2.3. Number of parameters computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba9c0a898796ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in=5\n",
    "num_responses=13\n",
    "metadata['num_item_id']*num_responses*d_in+metadata['num_user_id']*metadata['num_dimension_id']+metadata['num_dimension_id']*metadata['num_dimension_id']*d_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d574559bd418d77",
   "metadata": {},
   "source": [
    "### 3. CDM Prediction\n",
    "#### 3.1. Parallel training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c944f807c2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipcluster start --n=4\n",
    "#ipcluster stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a30ea4ddf5e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from ipyparallel import Client\n",
    "from IMPACT import utils\n",
    "import dill\n",
    "\n",
    "cat_absolute_path = os.path.abspath('../../')\n",
    "\n",
    "rc = Client()\n",
    "rc[:].use_dill()\n",
    "lview = rc.load_balanced_view()\n",
    "\n",
    "# Synchronize imports with all engines:\n",
    "rc[:].execute(\"import sys; sys.path.append('\"+cat_absolute_path+\"')\")\n",
    "rc[:].execute(\"import os; os.chdir('./liriscat/experiments/notebook_examples')\")\n",
    "\n",
    "with rc[:].sync_imports():\n",
    "    from IMPACT import utils, model, dataset\n",
    "\n",
    "config[\"disable_tqdm\"] = True\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['early_stopping'] = True\n",
    "config['save_params']=True # Save all model parameters and save an array of the embeddings\n",
    "config['verbose_early_stopping'] = False\n",
    "config['esc'] = 'error'\n",
    "\n",
    "def launch_training(seed:int,config:dict,train_data,valid_data,test_data, concept_map) :\n",
    "    utils.set_seed(seed)\n",
    "    config['seed'] = seed\n",
    "\n",
    "    algo = model.IMPACT(**config)\n",
    "\n",
    "    # Init model\n",
    "    algo.init_model(train_data, valid_data)\n",
    "\n",
    "    # train model ----\n",
    "    algo.train(train_data, valid_data)\n",
    "\n",
    "    emb = algo.model.users_emb.weight.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"pc-er\" : []}\n",
    "\n",
    "    metrics[\"pc-er\"].append(algo.evaluate_emb(test_data,concept_map)['pc-er'])\n",
    "    eval = algo.evaluate_test(test_data)\n",
    "    metrics[\"rmse\"].append(eval[\"rmse\"].cpu().numpy().tolist())\n",
    "    metrics[\"mae\"].append(eval[\"mae\"].cpu().numpy().tolist())\n",
    "\n",
    "    return (metrics,emb)\n",
    "\n",
    "def fold_test(i_fold : int, dataset_name:str, config : dict) :\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Dataset downloading for doa and rm\n",
    "    warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "    concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "    metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "    concept_array, concept_lens=utils.preprocess_concept_map(concept_map)\n",
    "\n",
    "    # read datasets\n",
    "    train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "    valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "    test_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_test_quadruples_vert_{i_fold}.csv',\n",
    "                                encoding='utf-8').to_records(index=False,\n",
    "                                                             column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                            \"correct\": float,\"dimension_id\":int})\n",
    "\n",
    "    train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "    test_data = dataset.LoaderDataset(test_quadruplets, concept_map, metadata)\n",
    "\n",
    "    seeds_combinations = []\n",
    "    for seed in range(3) :\n",
    "        seeds_combinations.append((seed,lview.apply_async(launch_training,seed,config,train_data,valid_data,test_data, concept_map)))\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"pc-er\" : [], \"doa\": [], 'rm' : []}\n",
    "\n",
    "    for seed,async_result in seeds_combinations:\n",
    "        metric, emb = async_result.get()\n",
    "        # test model ----\n",
    "        logging.info(f\"Test done - seed : {seed}, i_fold : {i_fold}\")\n",
    "        for k in metric.keys():\n",
    "            metrics[k].extend(metric[k])\n",
    "\n",
    "        metrics[\"doa\"].append(np.mean(utils.evaluate_doa(emb,test_data.log_tensor.cpu().numpy(),metadata,concept_map)))\n",
    "        metrics[\"rm\"].append(np.mean(utils.compute_rm_fold(emb,test_quadruplets, concept_array, concept_lens)))\n",
    "        pd.DataFrame(emb).to_csv(\"../embs/\"+dataset_name+\"_IMPACT_cornac_Iter_fold\"+str(i_fold)+\"_seed_\"+str(seed)+\".csv\",index=False,header=False)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test(dataset_name:str, config : dict) :\n",
    "\n",
    "    logging.info(f'#### {dataset_name} ####')\n",
    "    logging.info(f'#### config : {config} ####')\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"pc-er\" : [], \"doa\": [], 'rm' : []}\n",
    "\n",
    "    fold_combinations = []\n",
    "    for i_fold in range(5):\n",
    "        fold_combinations.append(fold_test(i_fold,dataset_name, config))\n",
    "\n",
    "    for metric in fold_combinations:\n",
    "        for k in metrics.keys():\n",
    "            metrics[k].extend(metric[k])\n",
    "\n",
    "    df = pd.DataFrame(metrics)\n",
    "    logging.info('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(), df['rmse'].std()))\n",
    "    logging.info('mae : {:.4f} +- {:.4f}'.format(df['mae'].mean(), df['mae'].std()))\n",
    "    logging.info('pc-er : {:.4f} +- {:.4f}'.format(df['pc-er'].mean(), df['pc-er'].std()))\n",
    "    logging.info('doa : {:.4f} +- {:.4f}'.format(df['doa'].mean(), df['doa'].std()))\n",
    "    logging.info('rm : {:.4f} +- {:.4f}'.format(df['rm'].mean(), df['rm'].std()))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aff2fe42621c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dataset_name = \"postcovid\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"movielens\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02515\n",
    "config['lambda'] = 2e-7\n",
    "config['d_in'] = 10\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"portrait\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.04568\n",
    "config['lambda'] = 2e-7\n",
    "config['d_in'] = 6\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"promis\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.01227\n",
    "config['lambda'] = 1e-7\n",
    "config['d_in'] = 6\n",
    "config['num_responses'] = 13\n",
    "metrics = test(dataset_name,config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e6c9c01a718e0",
   "metadata": {},
   "source": [
    "#### 3.2. Sequential training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59be7fecafcada09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "\n",
    "config[\"disable_tqdm\"] = True\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['early_stopping'] = True\n",
    "config['save_params']=False # Save all model parameters and save an array of the embeddings\n",
    "config['num_epochs']=2\n",
    "config['verbose_early_stopping'] = False\n",
    "config['esc'] = 'error'\n",
    "\n",
    "def test(dataset_name:str, config : dict) :\n",
    "\n",
    "    logging.info(f'#### {dataset_name} ####')\n",
    "    logging.info(f'#### config : {config} ####')\n",
    "    config['embs_path']='../embs/'+str(dataset_name)\n",
    "    config['params_path']='../ckpt/'+str(dataset_name)\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"pc-er\" : [], \"doa\": [], 'rm' : []}\n",
    "\n",
    "    for i_fold in range(1):\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Dataset downloading for doa and rm\n",
    "        warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "        concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "        concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "        metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "        concept_array, concept_lens=utils.preprocess_concept_map(concept_map)\n",
    "\n",
    "        # read datasets\n",
    "        train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                                     encoding='utf-8').to_records(index=False,\n",
    "                                                                  column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                                 \"correct\": float,\"dimension_id\":int})\n",
    "        valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                     encoding='utf-8').to_records(index=False,\n",
    "                                                                  column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                                 \"correct\": float,\"dimension_id\":int})\n",
    "        test_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_test_quadruples_vert_{i_fold}.csv',\n",
    "                                    encoding='utf-8').to_records(index=False,\n",
    "                                                                 column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                                \"correct\": float,\"dimension_id\":int})\n",
    "\n",
    "        train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "        valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "        test_data = dataset.LoaderDataset(test_quadruplets, concept_map, metadata)\n",
    "\n",
    "        for seed in range(2):\n",
    "    \n",
    "            # Set the seed\n",
    "            utils.set_seed(seed)\n",
    "            config['seed'] = seed\n",
    "\n",
    "            algo = model.IMPACT(**config)\n",
    "\n",
    "            # Init model\n",
    "            algo.init_model(train_data, valid_data)\n",
    "\n",
    "            # train model ----\n",
    "            algo.train(train_data, valid_data)\n",
    "\n",
    "            # test model ----\n",
    "             # test model ----\n",
    "            metrics[\"pc-er\"].append(algo.evaluate_emb(test_data,concept_map)['pc-er'])\n",
    "            eval = algo.evaluate_test(test_data)\n",
    "            metrics[\"rmse\"].append(eval[\"rmse\"].cpu().numpy())\n",
    "            metrics[\"mae\"].append(eval[\"mae\"].cpu().numpy())\n",
    "            emb = algo.model.users_emb.weight.detach().cpu().numpy()\n",
    "            metrics[\"doa\"].append(np.mean(utils.evaluate_doa(emb,test_data.log_tensor.cpu().numpy(),metadata,concept_map)))\n",
    "            metrics[\"rm\"].append(np.mean(utils.compute_rm_fold(emb,test_quadruplets, concept_array, concept_lens)))\n",
    "\n",
    "            pd.DataFrame(emb).to_csv(\"../embs/\"+dataset_name+\"_IMPACT_cornac_Iter_fold\"+str(i_fold)+\"_seed_\"+str(seed)+\".csv\",index=False,header=False)\n",
    "\n",
    "    df = pd.DataFrame(metrics)\n",
    "    logging.info('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(), df['rmse'].std()))\n",
    "    logging.info('mae : {:.4f} +- {:.4f}'.format(df['mae'].mean(), df['mae'].std()))\n",
    "    logging.info('pc-er : {:.4f} +- {:.4f}'.format(df['pc-er'].mean(), df['pc-er'].std()))\n",
    "    logging.info('doa : {:.4f} +- {:.4f}'.format(df['doa'].mean(), df['doa'].std()))\n",
    "    logging.info('rm : {:.4f} +- {:.4f}'.format(df['rm'].mean(), df['rm'].std()))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e5609a04d6a0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 57:47] assist0910\n",
      "[INFO 57:47] #### assist0910 ####\n",
      "[INFO 57:47] #### config : {'seed': 0, 'load_params': False, 'save_params': False, 'embs_path': '../embs/assist0910', 'params_path': '../ckpt/assist0910', 'early_stopping': True, 'fast_training': True, 'learning_rate': 0.02026, 'batch_size': 2048, 'num_epochs': 2, 'num_dim': 10, 'eval_freq': 1, 'patience': 30, 'device': device(type='cuda'), 'lambda': 1.2e-05, 'tensorboard': False, 'flush_freq': False, 'valid_metric': 'ma_acc', 'disable_tqdm': True, 'verbose_early_stopping': False, 'esc': 'error', 'd_in': 4, 'num_responses': 12} ####\n",
      "[INFO 57:57] train on cuda\n",
      "[INFO 57:57] -- START Training --\n",
      "[INFO 58:11] -- END Training --\n",
      "[INFO 58:27] train on cuda\n",
      "[INFO 58:27] -- START Training --\n",
      "[INFO 58:41] -- END Training --\n",
      "[INFO 58:53] rmse : 0.6016 +- 0.0031\n",
      "[INFO 58:53] mae : 0.3620 +- 0.0038\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'r2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'r2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 90\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataset_name, config)\u001b[0m\n\u001b[1;32m     88\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse : \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m +- \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd()))\n\u001b[1;32m     89\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae : \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m +- \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd()))\n\u001b[0;32m---> 90\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2 : \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m +- \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean(), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd()))\n\u001b[1;32m     91\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpc-er : \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m +- \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpc-er\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpc-er\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd()))\n\u001b[1;32m     92\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoa : \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m +- \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoa\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoa\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd()))\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'r2'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset_name = \"assist0910\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17019087789d375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dataset_name = \"postcovid\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"movielens\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02515\n",
    "config['lambda'] = 2e-7\n",
    "config['d_in'] = 10\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"portrait\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.04568\n",
    "config['lambda'] = 2e-7\n",
    "config['d_in'] = 6\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)\n",
    "\n",
    "dataset_name = \"promis\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.01227\n",
    "config['lambda'] = 1e-7\n",
    "config['d_in'] = 6\n",
    "config['num_responses'] = 13\n",
    "metrics = test(dataset_name,config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
