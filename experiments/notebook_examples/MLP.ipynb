{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MLP experiments\n",
    "### 1. Init\n",
    "#### 1.1. Import libraries"
   ],
   "id": "bc0774a07482a44f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T12:40:07.091469Z",
     "start_time": "2025-01-09T12:40:05.581617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from IMPACT import utils\n",
    "utils.set_seed(0)\n",
    "from IMPACT import dataset\n",
    "from IMPACT import model\n",
    "import optuna\n",
    "import logging\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from importlib import reload"
   ],
   "id": "30c2bf011793765d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2. Start tensorboard",
   "id": "6f4d550fa43938b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T13:26:27.657974Z",
     "start_time": "2025-01-02T13:26:26.890608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorboard import notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --reuse=False --logdir /home/arthurb/Programmation/liriscat/experiments/tensorboard --load_fast=false --reload_interval=1 \n",
    "\n",
    "print(notebook.list())\n",
    "# access tensorboard at : http://localhost:6006"
   ],
   "id": "db4f414458219d16",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m notebook\n\u001B[1;32m      2\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload_ext\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorboard\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtensorboard\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m--reuse=False --logdir /home/arthurb/Programmation/liriscat/experiments/tensorboard --load_fast=false --reload_interval=1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(notebook\u001B[38;5;241m.\u001B[39mlist())\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# access tensorboard at : http://localhost:6006\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2480\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2478\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[1;32m   2479\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[0;32m-> 2480\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2482\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2483\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2484\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/tensorboard/notebook.py:117\u001B[0m, in \u001B[0;36m_start_magic\u001B[0;34m(line)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_start_magic\u001B[39m(line):\n\u001B[1;32m    116\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/tensorboard/notebook.py:152\u001B[0m, in \u001B[0;36mstart\u001B[0;34m(args_string)\u001B[0m\n\u001B[1;32m    149\u001B[0m         handle\u001B[38;5;241m.\u001B[39mupdate(IPython\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mPretty(message))\n\u001B[1;32m    151\u001B[0m parsed_args \u001B[38;5;241m=\u001B[39m shlex\u001B[38;5;241m.\u001B[39msplit(args_string, comments\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, posix\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 152\u001B[0m start_result \u001B[38;5;241m=\u001B[39m \u001B[43mmanager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparsed_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(start_result, manager\u001B[38;5;241m.\u001B[39mStartLaunched):\n\u001B[1;32m    155\u001B[0m     _display(\n\u001B[1;32m    156\u001B[0m         port\u001B[38;5;241m=\u001B[39mstart_result\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mport,\n\u001B[1;32m    157\u001B[0m         print_message\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    158\u001B[0m         display_handle\u001B[38;5;241m=\u001B[39mhandle,\n\u001B[1;32m    159\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/tensorboard/manager.py:442\u001B[0m, in \u001B[0;36mstart\u001B[0;34m(arguments, timeout)\u001B[0m\n\u001B[1;32m    440\u001B[0m end_time_seconds \u001B[38;5;241m=\u001B[39m start_time_seconds \u001B[38;5;241m+\u001B[39m timeout\u001B[38;5;241m.\u001B[39mtotal_seconds()\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m<\u001B[39m end_time_seconds:\n\u001B[0;32m--> 442\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoll_interval_seconds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    443\u001B[0m     subprocess_result \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mpoll()\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m subprocess_result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3. Set up the loggers",
   "id": "18c248901436fb79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T12:40:11.439684Z",
     "start_time": "2025-01-09T12:40:10.431509Z"
    }
   },
   "cell_type": "code",
   "source": "utils.setuplogger(verbose = True, log_name=\"MLP_postcovid\")",
   "id": "f544e590b910dcad",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.5. Parametrize the datasets",
   "id": "61158521634c09ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T13:58:13.931424Z",
     "start_time": "2025-01-09T13:58:13.910555Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c4664f14b5fe9ad1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 58:13] #### postcovid ####\n",
      "[INFO 58:13] #### config : {'seed': 0, 'load_params': False, 'save_params': False, 'embs_path': '../embs/postcovid', 'params_path': '../ckpt/postcovid', 'early_stopping': True, 'fast_training': True, 'learning_rate': 0.001, 'batch_size': 2048, 'num_epochs': 200, 'num_dim': 10, 'eval_freq': 1, 'patience': 30, 'device': 'cuda:0', 'lambda': 7.7e-06, 'tensorboard': False, 'flush_freq': True, 'prednet_len1': 128, 'prednet_len2': 64, 'best_params_path': '', 'num_layers': 0, 'version': 'pair', 'p_dropout': 0, 'low_mem_mode': True, 'user_nbrs_n': 10, 'item_nbrs_n': 5} ####\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# choose dataset here\n",
    "dataset_name = 'postcovid'\n",
    "version= \"\"#\"_small\"\n",
    "# modify config here\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "config = {\n",
    "\n",
    "    # General params\n",
    "    'seed' : 0,\n",
    "\n",
    "    # Saving params\n",
    "    'load_params': False,\n",
    "    'save_params': False,\n",
    "    'embs_path' : '../embs/'+str(dataset_name),\n",
    "    'params_path' :'../ckpt/'+str(dataset_name),\n",
    "\n",
    "    # training mode\n",
    "    'early_stopping' : True,\n",
    "    'fast_training' : True, # (Only taken in account if early_stopping == true) If true, doesn't compute valid rmse PC-ER\n",
    "\n",
    "    # Learning params\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 2048,\n",
    "    'num_epochs': 200,\n",
    "    'num_dim': 10, # for IRT or MIRT todo : is it necessary as we use concepts knowledge number as embedding dimension ?\n",
    "    'eval_freq' : 1,\n",
    "    'patience' : 30,\n",
    "    'device': device,\n",
    "    'lambda' : 7.7e-6,\n",
    "    'tensorboard': False,\n",
    "    'flush_freq' : True,\n",
    "\n",
    "    # Testing params\n",
    "    'test_batch_size' : 10000,\n",
    "\n",
    "    # for NeuralCD\n",
    "    'prednet_len1': 128,\n",
    "    'prednet_len2': 64,\n",
    "    'best_params_path':'',\n",
    "\n",
    "    #For GCCD\n",
    "    'num_layers': 0,\n",
    "    'version': 'pair',\n",
    "    'p_dropout': 0,\n",
    "    'low_mem_mode' : True,\n",
    "    'user_nbrs_n' : 10,\n",
    "    'item_nbrs_n' : 5\n",
    "}\n",
    "concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "utils.set_seed(config['seed'])\n",
    "dataset_name += version\n",
    "logging.info(f'#### {dataset_name} ####')\n",
    "logging.info(f'#### config : {config} ####')"
   ],
   "id": "2fb60b17ffe8cb6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. CDM Hyperparameter search",
   "id": "2eecb5813a4dcd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1. Sequential",
   "id": "7f8a6aadbcd3a357"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T13:58:27.962060Z",
     "start_time": "2025-01-09T13:58:27.764548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "\n",
    "\n",
    "seed = 0\n",
    "utils.set_seed(0)\n",
    "\n",
    "config['seed'] = seed\n",
    "config['early_stopping'] = True\n",
    "config['esc'] = 'error'#'objectives' #'loss' 'delta_objectives'\n",
    "config['num_epochs']=200\n",
    "config['eval_freq']=1\n",
    "config['patience']=30\n",
    "\n",
    "config['verbose_early_stopping'] = False\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['save_params']= False\n",
    "config['disable_tqdm'] = True\n",
    "\n",
    "\n",
    "    \n",
    "def load_dataset(dataset_name : str) :\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # read datasets\n",
    "    i_fold = 0\n",
    "    concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "    concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "    metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "    train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                             encoding='utf-8').to_records(index=False,\n",
    "                                                          column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                         \"correct\": float,\"dimension_id\":int})\n",
    "    valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "    \n",
    "    train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "    \n",
    "    return train_data,valid_data,concept_map,metadata\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 5e-2, log=True)\n",
    "    lambda_param = trial.suggest_float('lambda', 1e-7, 5e-4, log=True)\n",
    "    d_in =  trial.suggest_int('d_in', 3,5)\n",
    "    num_responses = trial.suggest_int('num_responses', 9,13)\n",
    "    \n",
    "    config['learning_rate'] = lr\n",
    "    config['lambda'] = lambda_param\n",
    "    config['d_in'] =d_in\n",
    "    config['num_responses'] =num_responses\n",
    "    \n",
    "    algo = model.NN(**config)\n",
    "        \n",
    "    # Init model\n",
    "    algo.init_model(train_data, valid_data)\n",
    "\n",
    "    # train model ----\n",
    "    algo.train(train_data, valid_data)\n",
    "    \n",
    "    best_valid_rmse = algo.best_valid_rmse\n",
    "    \n",
    "    logging.info(\"-------Trial number : \"+str(trial.number)+\"\\nBest epoch : \"+str(algo.best_epoch)+\"\\nValues : [\"+str(best_valid_rmse)+\"]\\nParams : \"+str(trial.params))\n",
    "    \n",
    "    del algo.model\n",
    "    del algo   \n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "                \n",
    "    return best_valid_rmse"
   ],
   "id": "53c3976f69491bab",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T16:23:21.949421Z",
     "start_time": "2025-01-09T16:23:21.943635Z"
    }
   },
   "cell_type": "code",
   "source": "60*60*4",
   "id": "709e5728e8aa53f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14400"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T13:58:32.366571Z",
     "start_time": "2025-01-09T13:58:29.119653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_name = \"postcovid\"\n",
    "logging.info(dataset_name)\n",
    "train_data,valid_data,concept_map,metadata = load_dataset(dataset_name)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    directions=[\"minimize\"],  # Specify directions for each objective\n",
    ")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "study.optimize(objective, n_trials=2, n_jobs=1, gc_after_trial=True)\n",
    "\n",
    "# Analyze the results\n",
    "## requirements : plotly, nbformat\n",
    "pareto_trials = study.best_trials\n",
    "\n",
    "logging.info(f\"Best trial for {dataset_name} : {study.best_trials}\")\n",
    "for trial in pareto_trials:\n",
    "    logging.info(f\"Trial #{trial.number}\")\n",
    "    logging.info(f\"  RMSE: {trial.values}\")\n",
    "    #logging.info(f\"  DOA: {trial.values[1]}\")\n",
    "    logging.info(f\"  Params: {trial.params}\")"
   ],
   "id": "b7f525cc9a1b247f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 58:29] postcovid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 14:58:29,828] A new study created in memory with name: no-name-c78a6c4f-b3dc-45f3-a895-beabd90a1181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 58:30] train on cuda:0\n",
      "[INFO 58:30] -- START Training --\n",
      "[INFO 58:30] -- END Training --\n",
      "[INFO 58:30] -------Trial number : 0\n",
      "Best epoch : 2\n",
      "Values : [tensor(1.5509)]\n",
      "Params : {'learning_rate': 0.0003464206927619886, 'lambda': 6.517050926564996e-06, 'd_in': 4, 'num_responses': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 14:58:31,054] Trial 0 finished with value: 1.5509446859359741 and parameters: {'learning_rate': 0.0003464206927619886, 'lambda': 6.517050926564996e-06, 'd_in': 4, 'num_responses': 10}. Best is trial 0 with value: 1.5509446859359741.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 58:31] train on cuda:0\n",
      "[INFO 58:31] -- START Training --\n",
      "[INFO 58:32] -- END Training --\n",
      "[INFO 58:32] -------Trial number : 1\n",
      "Best epoch : 2\n",
      "Values : [tensor(0.3824)]\n",
      "Params : {'learning_rate': 0.004632994278645952, 'lambda': 1.9929011720513556e-06, 'd_in': 3, 'num_responses': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 14:58:32,271] Trial 1 finished with value: 0.3823884129524231 and parameters: {'learning_rate': 0.004632994278645952, 'lambda': 1.9929011720513556e-06, 'd_in': 3, 'num_responses': 12}. Best is trial 1 with value: 0.3823884129524231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 58:32] Best trial for postcovid : [FrozenTrial(number=1, state=1, values=[0.3823884129524231], datetime_start=datetime.datetime(2025, 1, 9, 14, 58, 31, 152198), datetime_complete=datetime.datetime(2025, 1, 9, 14, 58, 32, 271169), params={'learning_rate': 0.004632994278645952, 'lambda': 1.9929011720513556e-06, 'd_in': 3, 'num_responses': 12}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.05, log=True, low=1e-05, step=None), 'lambda': FloatDistribution(high=0.0005, log=True, low=1e-07, step=None), 'd_in': IntDistribution(high=5, log=False, low=3, step=1), 'num_responses': IntDistribution(high=13, log=False, low=9, step=1)}, trial_id=1, value=None)]\n",
      "[INFO 58:32] Trial #1\n",
      "[INFO 58:32]   RMSE: [0.3823884129524231]\n",
      "[INFO 58:32]   Params: {'learning_rate': 0.004632994278645952, 'lambda': 1.9929011720513556e-06, 'd_in': 3, 'num_responses': 12}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2. Parallelized",
   "id": "62dd8fde44ffb96d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#ipcluster start --n=3\n",
    "#ipcluster stop\n",
    "\n",
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "from ipyparallel import Client\n",
    "import dill\n",
    "\n",
    "cat_absolute_path = os.path.abspath('../../')\n",
    "\n",
    "rc = Client()\n",
    "rc[:].use_dill()\n",
    "lview = rc.load_balanced_view()\n",
    "\n",
    "\n",
    "rc[:].execute(\"import sys; sys.path.append('\"+cat_absolute_path+\"')\")\n",
    "print(\"sys.path.append(\"+cat_absolute_path+\")\")\n",
    "with rc[:].sync_imports():\n",
    "    import json\n",
    "    from IMPACT import utils, model, dataset\n",
    "    import logging\n",
    "    import gc\n",
    "    import torch\n",
    "\n",
    "seed = 0\n",
    "utils.set_seed(0)\n",
    "\n",
    "config['seed'] = seed\n",
    "config['early_stopping'] = True\n",
    "config['esc'] = 'error'#'objectives' #'loss' 'delta_objectives'\n",
    "config['num_epochs']=200\n",
    "config['eval_freq']=1\n",
    "config['patience']=30\n",
    "\n",
    "config['verbose_early_stopping'] = False\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['save_params']= False\n",
    "config['disable_tqdm'] = True\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(dataset_name : str) :\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # read datasets\n",
    "    i_fold = 0\n",
    "    concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "    concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "    metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "    train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                             encoding='utf-8').to_records(index=False,\n",
    "                                                          column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                         \"correct\": float,\"dimension_id\":int})\n",
    "    valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\"dimension_id\":int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "\n",
    "    train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "\n",
    "    return train_data,valid_data,concept_map,metadata\n",
    "\n",
    "def launch_test(trial,train_data,valid_data,config) :\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    algo = model.MLP(**config)\n",
    "\n",
    "    # Init model\n",
    "    algo.init_model(train_data, valid_data)\n",
    "\n",
    "    # train model ----\n",
    "    algo.train(train_data, valid_data)\n",
    "\n",
    "    best_valid_rmse = algo.best_valid_rmse\n",
    "\n",
    "    logging.info(\"-------Trial number : \"+str(trial.number)+\"\\nBest epoch : \"+str(algo.best_epoch)+\"\\nValues : [\"+str(best_valid_rmse)+\"]\\nParams : \"+str(trial.params))\n",
    "\n",
    "    del algo.model\n",
    "    del algo\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return best_valid_rmse\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    lr = trial.suggest_float('learning_rate', 0.001, 0.01, log=True)\n",
    "    lambda_param = trial.suggest_float('lambda', 1.2e-6, 1.6e-6, log=True)\n",
    "    d_in =  trial.suggest_int('d_in', 5,7)\n",
    "    num_responses = trial.suggest_int('num_responses', 11,13)\n",
    "\n",
    "    config['learning_rate'] = lr\n",
    "    config['lambda'] = lambda_param\n",
    "    config['d_in'] =d_in\n",
    "    config['num_responses'] =num_responses\n",
    "\n",
    "    return lview.apply_async(launch_test,trial,train_data,valid_data, config).get()\n",
    "\n"
   ],
   "id": "1c938ca9da1d7b10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%time\n",
    "dataset_name = \"movielens\"\n",
    "logging.info(dataset_name)\n",
    "train_data,valid_data,concept_map,metadata = load_dataset(dataset_name)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    directions=[\"minimize\"],  # Specify directions for each objective\n",
    ")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "study.optimize(objective, n_trials=100, n_jobs=3, gc_after_trial=True)\n",
    "\n",
    "# Analyze the results\n",
    "## requirements : plotly, nbformat\n",
    "pareto_trials = study.best_trials\n",
    "\n",
    "logging.info(f\"Best trial for {dataset_name} : {study.best_trials}\")\n",
    "for trial in pareto_trials:\n",
    "    logging.info(f\"Trial #{trial.number}\")\n",
    "    logging.info(f\"  RMSE: {trial.values}\")\n",
    "    #logging.info(f\"  DOA: {trial.values[1]}\")\n",
    "    logging.info(f\"  Params: {trial.params}\")"
   ],
   "id": "2903754279c264b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.3. Number of parameters computation",
   "id": "da61a9e00a0211e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "d_in=5\n",
    "num_responses=13\n",
    "metadata['num_item_id']*num_responses*d_in+metadata['num_user_id']*metadata['num_dimension_id']+metadata['num_dimension_id']*metadata['num_dimension_id']*d_in"
   ],
   "id": "c1ba9c0a898796ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. CDM Prediction\n",
    "#### 3.1. Parallel training and testing"
   ],
   "id": "6d574559bd418d77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#ipcluster start --n=4\n",
    "#ipcluster stop"
   ],
   "id": "303c944f807c2383"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T13:26:39.369296Z",
     "start_time": "2025-01-02T13:26:39.294535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from ipyparallel import Client\n",
    "from IMPACT import utils\n",
    "import dill\n",
    "\n",
    "cat_absolute_path = os.path.abspath('../../')\n",
    "\n",
    "rc = Client()\n",
    "rc[:].use_dill()\n",
    "lview = rc.load_balanced_view()\n",
    "\n",
    "# Synchronize imports with all engines:\n",
    "rc[:].execute(\"import sys; sys.path.append('\"+cat_absolute_path+\"')\")\n",
    "rc[:].execute(\"import os; os.chdir('./liriscat/experiments/notebook_examples')\")\n",
    "\n",
    "with rc[:].sync_imports():\n",
    "    from IMPACT import utils, model, dataset\n",
    "\n",
    "config[\"disable_tqdm\"] = True\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['early_stopping'] = True\n",
    "config['save_params']=True # Save all model parameters and save an array of the embeddings\n",
    "config['verbose_early_stopping'] = False\n",
    "config['esc'] = 'error'\n",
    "\n",
    "def launch_training(seed:int,config:dict,train_data,valid_data,test_data,test_dataloader, concept_map) :\n",
    "    utils.set_seed(seed)\n",
    "    config['seed'] = seed\n",
    "\n",
    "    algo = model.MLP(**config)\n",
    "\n",
    "    # Init model\n",
    "    algo.init_model(train_data, valid_data)\n",
    "\n",
    "    # train model ----\n",
    "    algo.train(train_data, valid_data)\n",
    "\n",
    "    emb = algo.model.users_emb.weight.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"r2\":[], \"pc-er\" : []}\n",
    "\n",
    "    metrics[\"pc-er\"].append(algo.evaluate_emb(test_data,concept_map)['pc-er'])\n",
    "    eval = algo.evaluate_test(test_dataloader)\n",
    "    metrics[\"rmse\"].append(eval[\"rmse\"].numpy().tolist())\n",
    "    metrics[\"mae\"].append(eval[\"mae\"].numpy().tolist())\n",
    "    metrics[\"r2\"].append(eval[\"r2\"].numpy().tolist())\n",
    "\n",
    "    return (metrics,emb)\n",
    "\n",
    "def fold_test(i_fold : int, dataset_name:str, config : dict) :\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Dataset downloading for doa and rm\n",
    "    warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "    concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "    metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "    concept_array, concept_lens=utils.preprocess_concept_map(concept_map)\n",
    "\n",
    "    # read datasets\n",
    "    train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "    valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                             \"correct\": float,\"dimension_id\":int})\n",
    "    test_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_test_quadruples_vert_{i_fold}.csv',\n",
    "                                encoding='utf-8').to_records(index=False,\n",
    "                                                             column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                            \"correct\": float,\"dimension_id\":int})\n",
    "\n",
    "    train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "    test_data = dataset.LoaderDataset(test_quadruplets, concept_map, metadata)\n",
    "    test_dataloader = data.DataLoader(test_data, batch_size=config['test_batch_size'], shuffle=False)\n",
    "\n",
    "    seeds_combinations = []\n",
    "    for seed in range(3) :\n",
    "        seeds_combinations.append((seed,lview.apply_async(launch_training,seed,config,train_data,valid_data,test_data,test_dataloader, concept_map)))\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"r2\":[], \"pc-er\" : [], \"doa\": [], 'rm' : []}\n",
    "\n",
    "    for seed,async_result in seeds_combinations:\n",
    "        metric, emb = async_result.get()\n",
    "        # test model ----\n",
    "        logging.info(f\"Test done - seed : {seed}, i_fold : {i_fold}\")\n",
    "        for k in metric.keys():\n",
    "            metrics[k].extend(metric[k])\n",
    "\n",
    "        metrics[\"doa\"].append(np.mean(utils.evaluate_doa(emb,test_data.log_tensor.cpu().numpy(),metadata,concept_map)))\n",
    "        metrics[\"rm\"].append(np.mean(utils.compute_rm_fold(emb,test_quadruplets, concept_array, concept_lens)))\n",
    "        pd.DataFrame(emb).to_csv(\"../embs/\"+dataset_name+\"_MLP_cornac_Iter_fold\"+str(i_fold)+\"_seed_\"+str(seed)+\".csv\",index=False,header=False)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test(dataset_name:str, config : dict) :\n",
    "\n",
    "    logging.info(f'#### {dataset_name} ####')\n",
    "    logging.info(f'#### config : {config} ####')\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"r2\":[], \"pc-er\" : [], \"doa\": [], 'rm' : []}\n",
    "\n",
    "    fold_combinations = []\n",
    "    for i_fold in range(5):\n",
    "        fold_combinations.append(fold_test(i_fold,dataset_name, config))\n",
    "\n",
    "    for metric in fold_combinations:\n",
    "        for k in metrics.keys():\n",
    "            metrics[k].extend(metric[k])\n",
    "\n",
    "    df = pd.DataFrame(metrics)\n",
    "    logging.info('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(), df['rmse'].std()))\n",
    "    logging.info('mae : {:.4f} +- {:.4f}'.format(df['mae'].mean(), df['mae'].std()))\n",
    "    logging.info('r2 : {:.4f} +- {:.4f}'.format(df['r2'].mean(), df['r2'].std()))\n",
    "    logging.info('pc-er : {:.4f} +- {:.4f}'.format(df['pc-er'].mean(), df['pc-er'].std()))\n",
    "    logging.info('doa : {:.4f} +- {:.4f}'.format(df['doa'].mean(), df['doa'].std()))\n",
    "    logging.info('rm : {:.4f} +- {:.4f}'.format(df['rm'].mean(), df['rm'].std()))\n",
    "\n",
    "    return metrics"
   ],
   "id": "d8a30ea4ddf5e7b2",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dill'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mipyparallel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Client\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mCAT\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdill\u001B[39;00m\n\u001B[1;32m     11\u001B[0m cat_absolute_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../../\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     13\u001B[0m rc \u001B[38;5;241m=\u001B[39m Client()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dill'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T13:26:40.315069Z",
     "start_time": "2025-01-02T13:26:40.277544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "dataset_name = \"postcovid\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)"
   ],
   "id": "d2aff2fe42621c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 26:40] postcovid\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:7\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'test' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.2. Sequential training and testing",
   "id": "f79e6c9c01a718e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T16:07:56.074087Z",
     "start_time": "2025-01-04T16:07:55.685065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n",
    "\n",
    "config[\"disable_tqdm\"] = True\n",
    "config[\"tensorboard\"] = False\n",
    "config['flush_freq'] = False\n",
    "config['early_stopping'] = True\n",
    "config['save_params']=False # Save all model parameters and save an array of the embeddings\n",
    "config['num_epochs']=200\n",
    "config['verbose_early_stopping'] = False\n",
    "config['esc'] = 'error'\n",
    "\n",
    "def test(dataset_name:str, config : dict) :\n",
    "\n",
    "    logging.info(f'#### {dataset_name} ####')\n",
    "    logging.info(f'#### config : {config} ####')\n",
    "    config['embs_path']='../embs/'+str(dataset_name)\n",
    "    config['params_path']='../ckpt/'+str(dataset_name)\n",
    "\n",
    "    metrics = {\"mae\":[],\"rmse\":[], \"r2\":[], \"pc-er\" : [], \"doa\": [], 'rm' : []}\n",
    "\n",
    "    for i_fold in range(5):\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Dataset downloading for doa and rm\n",
    "        warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "        concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "        concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "        metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))\n",
    "        concept_array, concept_lens=utils.preprocess_concept_map(concept_map)\n",
    "\n",
    "        # read datasets\n",
    "        train_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_train_quadruples_vert_{i_fold}.csv',\n",
    "                                     encoding='utf-8').to_records(index=False,\n",
    "                                                                  column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                                 \"correct\": float,\"dimension_id\":int})\n",
    "        valid_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_valid_quadruples_vert_{i_fold}.csv',\n",
    "                                     encoding='utf-8').to_records(index=False,\n",
    "                                                                  column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                                 \"correct\": float,\"dimension_id\":int})\n",
    "        test_quadruplets = pd.read_csv(f'../datasets/2-preprocessed_data/{dataset_name}_test_quadruples_vert_{i_fold}.csv',\n",
    "                                    encoding='utf-8').to_records(index=False,\n",
    "                                                                 column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                                \"correct\": float,\"dimension_id\":int})\n",
    "\n",
    "        train_data = dataset.LoaderDataset(train_quadruplets, concept_map, metadata)\n",
    "        valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "        test_data = dataset.LoaderDataset(test_quadruplets, concept_map, metadata)\n",
    "        test_dataloader = data.DataLoader(test_data, batch_size=config['test_batch_size'], shuffle=False)\n",
    "\n",
    "        for seed in range(1):\n",
    "    \n",
    "            # Set the seed\n",
    "            utils.set_seed(seed)\n",
    "            config['seed'] = seed\n",
    "\n",
    "            algo = model.MLP(**config)\n",
    "\n",
    "            # Init model\n",
    "            algo.init_model(train_data, valid_data)\n",
    "\n",
    "            # train model ----\n",
    "            algo.train(train_data, valid_data)\n",
    "\n",
    "            # test model ----\n",
    "             # test model ----\n",
    "            metrics[\"pc-er\"].append(algo.evaluate_emb(test_data,concept_map)['pc-er'])\n",
    "            eval = algo.evaluate_test(test_dataloader)\n",
    "            metrics[\"rmse\"].append(eval[\"rmse\"].numpy())\n",
    "            metrics[\"mae\"].append(eval[\"mae\"].numpy())\n",
    "            metrics[\"r2\"].append(eval[\"r2\"].numpy())\n",
    "            emb = algo.model.users_emb.weight.detach().cpu().numpy()\n",
    "            metrics[\"doa\"].append(np.mean(utils.evaluate_doa(emb,test_data.log_tensor.cpu().numpy(),metadata,concept_map)))\n",
    "            metrics[\"rm\"].append(np.mean(utils.compute_rm_fold(emb,test_quadruplets, concept_array, concept_lens)))\n",
    "\n",
    "            pd.DataFrame(emb).to_csv(\"../embs/\"+dataset_name+\"_MLP_cornac_Iter_fold\"+str(i_fold)+\"_seed_\"+str(seed)+\".csv\",index=False,header=False)\n",
    "\n",
    "    df = pd.DataFrame(metrics)\n",
    "    logging.info('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(), df['rmse'].std()))\n",
    "    logging.info('mae : {:.4f} +- {:.4f}'.format(df['mae'].mean(), df['mae'].std()))\n",
    "    logging.info('r2 : {:.4f} +- {:.4f}'.format(df['r2'].mean(), df['r2'].std()))\n",
    "    logging.info('pc-er : {:.4f} +- {:.4f}'.format(df['pc-er'].mean(), df['pc-er'].std()))\n",
    "    logging.info('doa : {:.4f} +- {:.4f}'.format(df['doa'].mean(), df['doa'].std()))\n",
    "    logging.info('rm : {:.4f} +- {:.4f}'.format(df['rm'].mean(), df['rm'].std()))\n",
    "\n",
    "    return metrics"
   ],
   "id": "59be7fecafcada09",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T16:08:06.132819Z",
     "start_time": "2025-01-04T16:07:56.080471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "dataset_name = \"postcovid\"\n",
    "logging.info(dataset_name)\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "metrics = test(dataset_name,config)"
   ],
   "id": "17019087789d375a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 07:56] postcovid\n",
      "[INFO 07:56] #### postcovid ####\n",
      "[INFO 07:56] #### config : {'seed': 0, 'load_params': False, 'save_params': False, 'embs_path': '../embs/postcovid', 'params_path': '../ckpt/postcovid', 'early_stopping': True, 'fast_training': True, 'learning_rate': 0.02026, 'batch_size': 2048, 'num_epochs': 200, 'num_dim': 10, 'eval_freq': 1, 'patience': 30, 'device': 'cuda:0', 'lambda': 1.2e-05, 'tensorboard': False, 'flush_freq': False, 'prednet_len1': 128, 'prednet_len2': 64, 'best_params_path': '', 'num_layers': 0, 'version': 'pair', 'p_dropout': 0, 'low_mem_mode': True, 'user_nbrs_n': 10, 'item_nbrs_n': 5, 'disable_tqdm': True, 'verbose_early_stopping': False, 'esc': 'error', 'd_in': 4, 'num_responses': 12} ####\n",
      "[INFO 07:56] train on cuda:0\n",
      "[INFO 07:56] -- START Training --\n",
      "[INFO 08:05] -- END Training --\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:7\u001B[0m\n",
      "Cell \u001B[0;32mIn[12], line 77\u001B[0m, in \u001B[0;36mtest\u001B[0;34m(dataset_name, config)\u001B[0m\n\u001B[1;32m     73\u001B[0m algo\u001B[38;5;241m.\u001B[39mtrain(train_data, valid_data)\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# test model ----\u001B[39;00m\n\u001B[1;32m     76\u001B[0m  \u001B[38;5;66;03m# test model ----\u001B[39;00m\n\u001B[0;32m---> 77\u001B[0m metrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpc-er\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(\u001B[43malgo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_emb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43mconcept_map\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpc-er\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28meval\u001B[39m \u001B[38;5;241m=\u001B[39m algo\u001B[38;5;241m.\u001B[39mevaluate_test(test_data)\n\u001B[1;32m     79\u001B[0m metrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrmse\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28meval\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrmse\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "File \u001B[0;32m~/Programmation/liriscat/CAT/model/abstract_model.py:832\u001B[0m, in \u001B[0;36mAbstractContinuousModel.evaluate_emb\u001B[0;34m(self, dataloader, concept_map)\u001B[0m\n\u001B[1;32m    830\u001B[0m             c \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m corr\n\u001B[1;32m    831\u001B[0m             s \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 832\u001B[0m     \u001B[43mc\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpc-er\u001B[39m\u001B[38;5;124m'\u001B[39m : c\u001B[38;5;241m.\u001B[39mitem()}\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8b35dcf3559dbe89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
