{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9e923c5a6fbe3b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Experiments for CDM exclusively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:14:32.061535Z",
     "start_time": "2024-05-29T19:14:32.010732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'CAT'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 11\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m reload\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#import CAT\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#from CAT.dataset import *\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m#from CAT import utils\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mCAT\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m model\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'CAT'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "import DBPR\n",
    "from DBPR.dataset import *\n",
    "from DBPR import utils\n",
    "from DBPR import model\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "774c46a0b619fc02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:14:35.618254Z",
     "start_time": "2024-05-29T19:14:35.611034Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def setuplogger():\n",
    "    root = logging.getLogger()\n",
    "    root.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\"[%(levelname)s %(asctime)s] %(message)s\")\n",
    "    formatter.default_time_format = \"%M:%S\"\n",
    "    formatter.default_msec_format = \"\"\n",
    "    handler.setFormatter(formatter)\n",
    "    for handler in root.handlers[:]:\n",
    "        root.removeHandler(handler)\n",
    "    root.addHandler(handler)    \n",
    "setuplogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c9c72588f9c3af8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:14:36.121850Z",
     "start_time": "2024-05-29T19:14:36.112302Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# choose dataset here\n",
    "dataset_name = 'portrait'\n",
    "# modify config here\n",
    "config = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 2048,\n",
    "    'num_epochs': 1,\n",
    "    'num_dim': 10, # for IRT or MIRT todo : is it necessary as we use concepts knowledge number as embedding dimension ?\n",
    "    'eval_freq' : 1,\n",
    "    'patience' : 6,\n",
    "    'device': 'cpu',\n",
    "    'lambda' : 1e-7,\n",
    "    # for NeuralCD\n",
    "    'prednet_len1': 128,\n",
    "    'prednet_len2': 64,\n",
    "    'best_params_path':'../ckpt/',\n",
    "    #For GCCD\n",
    "    'num_layers': 0,\n",
    "    'version': 'pair',\n",
    "    'p_dropout': 0,\n",
    "    'low_mem_mode' : True,\n",
    "    'user_nbrs_n' : 10,\n",
    "    'item_nbrs_n' : 5\n",
    "}\n",
    "concept_map = json.load(open(f'../datasets/{dataset_name}/concept_map.json', 'r'))\n",
    "concept_map = {int(k):[int(x) for x in v] for k,v in concept_map.items()}\n",
    "metadata = json.load(open(f'../datasets/{dataset_name}/metadata.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3179426d9afedb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## CDM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aea370cc2fec03fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T12:02:40.704571Z",
     "start_time": "2024-05-28T12:02:34.439459Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low memory mode activated\n",
      "[INFO 02:35] train on cpu\n",
      "[INFO 02:35] -- START Training --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 54/76 [00:02<00:01, 21.63it/s]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x798b7a36ac90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/arthurb/anaconda3/envs/liriscat/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "100%|██████████| 76/76 [00:03<00:00, 19.52it/s]\n",
      " 29%|██▉       | 22/76 [00:01<00:02, 20.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 28\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# train model\u001B[39;00m\n\u001B[1;32m     27\u001B[0m algo\u001B[38;5;241m.\u001B[39minit_model(train_data)\n\u001B[0;32m---> 28\u001B[0m \u001B[43malgo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m test \u001B[38;5;241m=\u001B[39m algo\u001B[38;5;241m.\u001B[39mevaluate_test(test_data)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Programmation/liriscat/CAT/model/GCCDModel.py:646\u001B[0m, in \u001B[0;36mGCCD.train\u001B[0;34m(self, train_data, valid_data, test_data)\u001B[0m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;66;03m# U_nbrs_dist = torch.tensor(U_nbrs_dist,dtype=torch.float).to(device)\u001B[39;00m\n\u001B[1;32m    641\u001B[0m \u001B[38;5;66;03m# I_nbrs_dist = torch.tensor(I_nbrs_dist,dtype=torch.float).to(device)\u001B[39;00m\n\u001B[1;32m    642\u001B[0m \u001B[38;5;66;03m# print(f' U dist max : {torch.mean(torch.max(U_nbrs_dist,dim=1)[0].float())},min : {U_nbrs_dist.min(dim=1)[0].float().mean()}, std : {U_nbrs_dist.std(dim=1)[0].float().mean()},mean : {U_nbrs_dist.mean(dim=1)[0].float().mean()}')\u001B[39;00m\n\u001B[1;32m    643\u001B[0m \u001B[38;5;66;03m# print(f'I dist max : {I_nbrs_dist.max(dim=1)[0].float().mean()},min : {I_nbrs_dist.min(dim=1)[0].float().mean()}, std : {I_nbrs_dist.std(dim=1)[0].float().mean()},mean : {I_nbrs_dist.mean(dim=1)[0].float().mean()}')\u001B[39;00m\n\u001B[1;32m    645\u001B[0m loss_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 646\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcnt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconcepts_emb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    647\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    648\u001B[0m \u001B[43m    \u001B[49m\u001B[43muser_ids\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43muser_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[43mitem_ids\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mitem_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[1;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/torch/utils/data/dataloader.py:625\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 625\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprofiler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecord_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_profile_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    626\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sampler_iter\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;49;00m\n\u001B[1;32m    628\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-arg]\u001B[39;49;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/torch/autograd/profiler.py:689\u001B[0m, in \u001B[0;36mrecord_function.__exit__\u001B[0;34m(self, exc_type, exc_value, traceback)\u001B[0m\n\u001B[1;32m    684\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecord \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39m_record_function_enter_new(\n\u001B[1;32m    685\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\n\u001B[1;32m    686\u001B[0m     )\n\u001B[1;32m    687\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m--> 689\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001B[1;32m    690\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_callbacks_on_exit:\n\u001B[1;32m    691\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# grid_search\n",
    "for p_dropout in [0]:\n",
    "    config['p_dropout'] = p_dropout\n",
    "    for num_layers in [1]:\n",
    "        config['num_layers'] = num_layers\n",
    "        # read datasets\n",
    "        algo = model.GCCD(**config)\n",
    "        metrics = []\n",
    "            \n",
    "        for i_fold in range(1) :\n",
    "                           \n",
    "            train_triplets = pd.read_csv(f'../datasets/{dataset_name}/train_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "            valid_triplets = pd.read_csv(f'../datasets/{dataset_name}/valid_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "            test_triplets = pd.read_csv(f'../datasets/{dataset_name}/test_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "            \n",
    "            \n",
    "            train_data = dataset.LoaderDataset(train_triplets, concept_map, metadata)\n",
    "            valid_data = dataset.LoaderDataset(valid_triplets, concept_map, metadata) \n",
    "            test_data = dataset.LoaderDataset(test_triplets, concept_map,metadata) \n",
    "            # define model here\n",
    "        \n",
    "            for seed in range(1) : \n",
    "                # Set the seed\n",
    "                utils.set_seed(seed)\n",
    "                \n",
    "                # train model\n",
    "                algo.init_model(train_data, None)\n",
    "                algo.train(train_data, valid_data,test_data)\n",
    "                test = algo.evaluate_test(test_data)\n",
    "                print(f'test : {test}')\n",
    "                metrics.append(test)\n",
    "                \n",
    "        df = pd.DataFrame(metrics)\n",
    "        print(f'dropout : {config['p_dropout']}; num_layers : {config['num_layers']}')\n",
    "        print('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(),df['rmse'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949df350beb88b5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "print('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(),df['rmse'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a985e19d36960",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = [7192,7149,7139,7133,7130,7128,7127,7126,7126,7126,7126,7126,7126,7126]\n",
    "rmse_list = [2226,2039,1991,1964,1947,1940,1934,1930,1928,1927,1926,1926,1926,1926]\n",
    "U_mean_dist_list = [0.007051741238683462,0.010280357673764229,0.012986190617084503,0.016543250530958176,0.016660312190651894,0.018504280596971512,0.0225063469260931,0.024717843160033226,0.028801996260881424,0.026518404483795166,0.028305459767580032,0.02960900403559208,0.02976769208908081,0.030901530757546425]\n",
    "I_mean_dist_list = [0.004827531985938549,0.010112187825143337,0.015812134370207787,0.01486632227897644,0.023593515157699585,0.036251962184906006,0.03952261433005333,0.05163084343075752,0.061826325953006744,0.07495086640119553,0.07987217605113983,0.08609910309314728,0.08502209931612015,0.09476266801357269]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"RMSE, Loss, and embeddings ave distances of neigbors over training epochs\")\n",
    "plt.plot(range(len(loss_list)), loss_list, label='loss',c =\"orange\")\n",
    "plt.twinx()\n",
    "plt.plot(range(len(rmse_list)), rmse_list, label='rmse',c='b')\n",
    "plt.twinx()\n",
    "plt.plot(range(len(U_mean_dist_list)), U_mean_dist_list, label='U',c='red')\n",
    "plt.twinx()\n",
    "plt.plot(range(len(I_mean_dist_list)), I_mean_dist_list, label='I',c='yellow')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3347fcfebd3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ac481bee585f7fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:39:09.663786Z",
     "start_time": "2024-05-28T13:39:07.903921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-629f6fbed82c07cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-629f6fbed82c07cd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import tensorboardX\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir /home/arthurb/Programmation/liriscat/scripts/logs\n",
    "\n",
    "# Connect to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbd417b1283ed",
   "metadata": {},
   "source": [
    "Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0686d827bf2e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T17:41:10.876086Z",
     "start_time": "2024-05-29T17:39:47.907869Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20041929]\n",
      "[0.20041929, 0.20112045]\n",
      "[0.20041929, 0.20112045, 0.20127916]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 34\u001B[0m\n\u001B[1;32m     32\u001B[0m X_train \u001B[38;5;241m=\u001B[39m csr_matrix(train_valid_data\u001B[38;5;241m.\u001B[39mlog_tensor\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m     33\u001B[0m X_train \u001B[38;5;241m=\u001B[39m train_valid_data\u001B[38;5;241m.\u001B[39mlog_tensor\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m---> 34\u001B[0m \u001B[43mimp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m X_train \u001B[38;5;241m=\u001B[39m imp\u001B[38;5;241m.\u001B[39mtransform(X_train)\n\u001B[1;32m     36\u001B[0m algo\u001B[38;5;241m.\u001B[39mfit(X_train)\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/sklearn/impute/_iterative.py:875\u001B[0m, in \u001B[0;36mIterativeImputer.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    859\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit the imputer on `X` and return self.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m \n\u001B[1;32m    861\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    873\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[1;32m    874\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 875\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    876\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/sklearn/utils/_set_output.py:140\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 140\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    142\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    143\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    144\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    145\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    146\u001B[0m         )\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/sklearn/impute/_iterative.py:761\u001B[0m, in \u001B[0;36mIterativeImputer.fit_transform\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    757\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m feat_idx \u001B[38;5;129;01min\u001B[39;00m ordered_idx:\n\u001B[1;32m    758\u001B[0m     neighbor_feat_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_neighbor_feat_idx(\n\u001B[1;32m    759\u001B[0m         n_features, feat_idx, abs_corr_mat\n\u001B[1;32m    760\u001B[0m     )\n\u001B[0;32m--> 761\u001B[0m     Xt, estimator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_impute_one_feature\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    762\u001B[0m \u001B[43m        \u001B[49m\u001B[43mXt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmask_missing_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    764\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeat_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    765\u001B[0m \u001B[43m        \u001B[49m\u001B[43mneighbor_feat_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    766\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    767\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    768\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    769\u001B[0m     estimator_triplet \u001B[38;5;241m=\u001B[39m _ImputerTriplet(\n\u001B[1;32m    770\u001B[0m         feat_idx, neighbor_feat_idx, estimator\n\u001B[1;32m    771\u001B[0m     )\n\u001B[1;32m    772\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimputation_sequence_\u001B[38;5;241m.\u001B[39mappend(estimator_triplet)\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/sklearn/impute/_iterative.py:408\u001B[0m, in \u001B[0;36mIterativeImputer._impute_one_feature\u001B[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001B[0m\n\u001B[1;32m    398\u001B[0m     X_train \u001B[38;5;241m=\u001B[39m _safe_indexing(\n\u001B[1;32m    399\u001B[0m         _safe_indexing(X_filled, neighbor_feat_idx, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m),\n\u001B[1;32m    400\u001B[0m         \u001B[38;5;241m~\u001B[39mmissing_row_mask,\n\u001B[1;32m    401\u001B[0m         axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m    402\u001B[0m     )\n\u001B[1;32m    403\u001B[0m     y_train \u001B[38;5;241m=\u001B[39m _safe_indexing(\n\u001B[1;32m    404\u001B[0m         _safe_indexing(X_filled, feat_idx, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m),\n\u001B[1;32m    405\u001B[0m         \u001B[38;5;241m~\u001B[39mmissing_row_mask,\n\u001B[1;32m    406\u001B[0m         axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m    407\u001B[0m     )\n\u001B[0;32m--> 408\u001B[0m     \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[38;5;66;03m# if no missing values, don't predict\u001B[39;00m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39msum(missing_row_mask) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/sklearn/linear_model/_bayes.py:344\u001B[0m, in \u001B[0;36mBayesianRidge.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;66;03m# Convergence loop of the bayesian ridge regression\u001B[39;00m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m iter_ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_iter):\n\u001B[1;32m    342\u001B[0m     \u001B[38;5;66;03m# update posterior mean coef_ based on alpha_ and lambda_ and\u001B[39;00m\n\u001B[1;32m    343\u001B[0m     \u001B[38;5;66;03m# compute corresponding rmse\u001B[39;00m\n\u001B[0;32m--> 344\u001B[0m     coef_, rmse_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_coef_\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXT_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mU\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mVh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meigen_vals_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda_\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_score:\n\u001B[1;32m    348\u001B[0m         \u001B[38;5;66;03m# compute the log marginal likelihood\u001B[39;00m\n\u001B[1;32m    349\u001B[0m         s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_marginal_likelihood(\n\u001B[1;32m    350\u001B[0m             n_samples, n_features, eigen_vals_, alpha_, lambda_, coef_, rmse_\n\u001B[1;32m    351\u001B[0m         )\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/sklearn/linear_model/_bayes.py:434\u001B[0m, in \u001B[0;36mBayesianRidge._update_coef_\u001B[0;34m(self, X, y, n_samples, n_features, XT_y, U, Vh, eigen_vals_, alpha_, lambda_)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Update posterior mean and compute corresponding rmse.\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \n\u001B[1;32m    428\u001B[0m \u001B[38;5;124;03mPosterior mean is given by coef_ = scaled_sigma_ * X.T * y where\u001B[39;00m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;124;03mscaled_sigma_ = (lambda_/alpha_ * np.eye(n_features)\u001B[39;00m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;124;03m                 + np.dot(X.T, X))^-1\u001B[39;00m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_samples \u001B[38;5;241m>\u001B[39m n_features:\n\u001B[0;32m--> 434\u001B[0m     coef_ \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmulti_dot\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43mVh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mVh\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43meigen_vals_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlambda_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43malpha_\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnewaxis\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXT_y\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    438\u001B[0m     coef_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mmulti_dot(\n\u001B[1;32m    439\u001B[0m         [X\u001B[38;5;241m.\u001B[39mT, U \u001B[38;5;241m/\u001B[39m (eigen_vals_ \u001B[38;5;241m+\u001B[39m lambda_ \u001B[38;5;241m/\u001B[39m alpha_)[\u001B[38;5;28;01mNone\u001B[39;00m, :], U\u001B[38;5;241m.\u001B[39mT, y]\n\u001B[1;32m    440\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/numpy/linalg/linalg.py:2638\u001B[0m, in \u001B[0;36m_multidot_dispatcher\u001B[0;34m(arrays, out)\u001B[0m\n\u001B[1;32m   2633\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImproper number of dimensions to norm.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2636\u001B[0m \u001B[38;5;66;03m# multi_dot\u001B[39;00m\n\u001B[0;32m-> 2638\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_multidot_dispatcher\u001B[39m(arrays, \u001B[38;5;241m*\u001B[39m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   2639\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m arrays\n\u001B[1;32m   2640\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m out\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from DBPR.model import abstract_model as am \n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i_fold in range(5) :  \n",
    "    \n",
    "    # read datasets\n",
    "    train_triplets = pd.read_csv(f'../datasets/{dataset_name}/train_triples_vert_{i_fold}.csv', encoding='utf-8')\n",
    "    valid_triplets = pd.read_csv(f'../datasets/{dataset_name}/valid_triples_vert_{i_fold}.csv', encoding='utf-8')\n",
    "    test_triplets = pd.read_csv(f'../datasets/{dataset_name}/test_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False)\n",
    "\n",
    "    train_valid_triplets = pd.concat([train_triplets, valid_triplets]).to_records(index=False)   \n",
    "       \n",
    "    train_valid_data = dataset.LoaderDataset(train_valid_triplets, concept_map, metadata)\n",
    "    test_data = dataset.LoaderDataset(test_triplets, concept_map,metadata)\n",
    "    # define model here\n",
    "\n",
    "    for seed in range(1) : \n",
    "        algo = NMF(n_components=metadata[\"num_dimension_id\"], init='random',max_iter=10000, random_state=seed)\n",
    "        \n",
    "        # Set the seed\n",
    "        utils.set_seed(seed)\n",
    "        imp = IterativeImputer(max_iter=20, random_state=seed, missing_values=0.0,min_value=1.0, max_value=float(train_valid_data.log_tensor.max())) \n",
    "        \n",
    "        # train algo ----\n",
    "        # Impute missing data\n",
    "        X_train = csr_matrix(train_valid_data.log_tensor.numpy())\n",
    "        X_train = train_valid_data.log_tensor.numpy()\n",
    "        imp.fit(X_train)\n",
    "        X_train = imp.transform(X_train)\n",
    "        algo.fit(X_train)\n",
    "        \n",
    "        # test algo ----\n",
    "        X_test = test_data.log_tensor.numpy()\n",
    "        X_test = imp.transform(X_test)\n",
    "        users_emb = algo.transform(X_test)\n",
    "        items_emb = algo.components_\n",
    "        \n",
    "        y_true = test_data.log_tensor.reshape(-1).numpy()\n",
    "        y_pred = (users_emb @ items_emb).reshape(-1)\n",
    "        metrics.append(am.root_mean_squared_error(y_pred[y_true !=0],y_true[y_true !=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69ffec513fa68bc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:30:21.621779Z",
     "start_time": "2024-05-29T15:30:21.603803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse : 0.2017 +- 0.0010\n"
     ]
    }
   ],
   "source": [
    "print('rmse : {:.4f} +- {:.4f}'.format(np.mean(metrics),np.std(metrics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e2e1aff0be698f",
   "metadata": {},
   "source": [
    "SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "381c109730cb8d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T11:56:22.999348Z",
     "start_time": "2024-05-02T11:54:25.376128Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from DBPR.model import abstract_model as am \n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i_fold in range(5) :  \n",
    "    \n",
    "    # read datasets\n",
    "    train_triplets = pd.read_csv(f'../datasets/{dataset_name}/train_triples_vert_{i_fold}.csv', encoding='utf-8')\n",
    "    valid_triplets = pd.read_csv(f'../datasets/{dataset_name}/valid_triples_vert_{i_fold}.csv', encoding='utf-8')\n",
    "    test_triplets = pd.read_csv(f'../datasets/{dataset_name}/test_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False)\n",
    "\n",
    "    train_valid_triplets = pd.concat([train_triplets, valid_triplets]).to_records(index=False)   \n",
    "       \n",
    "    train_valid_data = dataset.LoaderDataset(train_valid_triplets, concept_map, metadata)\n",
    "    test_data = dataset.LoaderDataset(test_triplets, concept_map,metadata)\n",
    "    # define algo here\n",
    "\n",
    "    for seed in range(1) : \n",
    "        algo = TruncatedSVD(n_components=metadata[\"num_dimension_id\"], n_iter=10000, random_state=seed)\n",
    "        \n",
    "        # Set the seed\n",
    "        utils.set_seed(seed)\n",
    "        imp = IterativeImputer(max_iter=20, random_state=seed, missing_values=0.0,min_value=1.0, max_value=float(train_valid_data.log_tensor.max())) # todo : attention min value is 1\n",
    "        \n",
    "        # Impute missing data\n",
    "        #X_train = csr_matrix(train_valid_data.log_tensor.numpy())\n",
    "        X_train = train_valid_data.log_tensor.numpy()\n",
    "        imp.fit(X_train)\n",
    "        X_train = imp.transform(X_train)\n",
    "        # train algo\n",
    "        algo.fit(X_train)\n",
    "        \n",
    "        X_test = test_data.log_tensor.numpy()\n",
    "        X_test = imp.transform(X_test)\n",
    "        users_emb = algo.transform(X_test)\n",
    "        items_emb = algo.components_\n",
    "        \n",
    "        y_true = test_data.log_tensor.reshape(-1).numpy()\n",
    "        y_pred = (users_emb @ items_emb).reshape(-1)\n",
    "        metrics.append(am.root_mean_squared_error(y_pred[y_true !=0],y_true[y_true !=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d86826ff13ad1f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T11:56:23.013914Z",
     "start_time": "2024-05-02T11:56:23.000509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse : 2.426 +- 0.008\n"
     ]
    }
   ],
   "source": [
    "print('rmse : {:.4f} +- {:.4f}'.format(np.mean(metrics),np.std(metrics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8089194f09e5ddd0",
   "metadata": {},
   "source": [
    "Average response prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "605ebf3bdbfa2961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T11:26:58.542925Z",
     "start_time": "2024-05-27T11:26:01.267587Z"
    }
   },
   "outputs": [],
   "source": [
    "# read datasets\n",
    "algo = model.Averaging(**config)\n",
    "metrics = []\n",
    "    \n",
    "for i_fold in range(5) : \n",
    "                   \n",
    "    train_triplets = pd.read_csv(f'../datasets/{dataset_name}/train_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "    valid_triplets = pd.read_csv(f'../datasets/{dataset_name}/valid_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "    test_triplets = pd.read_csv(f'../datasets/{dataset_name}/test_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "    \n",
    "    \n",
    "    train_data = dataset.LoaderDataset(train_triplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_triplets, concept_map, metadata) # todo : unused for the moment\n",
    "    test_data = dataset.LoaderDataset(test_triplets, concept_map,metadata) \n",
    "    # define model here\n",
    "\n",
    "    for seed in range(1) : \n",
    "        # Set the seed\n",
    "        utils.set_seed(seed)\n",
    "        \n",
    "        # train model\n",
    "        algo.init_model(train_data, None)\n",
    "        metrics.append(algo.evaluate_test(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b602f2fb9e6450a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T11:27:19.430381Z",
     "start_time": "2024-05-27T11:27:19.415971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse : 0.4126 +- 0.0004\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "print('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(),df['rmse'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e43aa1a40dff9",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e518e4916c4304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:28:23.496813Z",
     "start_time": "2024-05-29T19:28:21.176350Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'users_emb'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 26\u001B[0m\n\u001B[1;32m     23\u001B[0m utils\u001B[38;5;241m.\u001B[39mset_seed(seed)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# train model\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m embeddings\u001B[38;5;241m.\u001B[39mappend(\u001B[43malgo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_user_emb\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     28\u001B[0m algo\u001B[38;5;241m.\u001B[39minit_model(train_data)\n\u001B[1;32m     29\u001B[0m algo\u001B[38;5;241m.\u001B[39mtrain(train_data, valid_data)\n",
      "File \u001B[0;32m~/Programmation/liriscat/CAT/model/NNModel.py:97\u001B[0m, in \u001B[0;36mNN.get_user_emb\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_user_emb\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;66;03m#super().get_user_emb()\u001B[39;00m\n\u001B[0;32m---> 97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43musers_emb\u001B[49m\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mdata\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'users_emb'"
     ]
    }
   ],
   "source": [
    "# read datasets\n",
    "from importlib import reload\n",
    "\n",
    "metrics = []\n",
    "embeddings = []\n",
    "config['learning_rate'] = 0.001\n",
    "\n",
    "for i_fold in range(5) : \n",
    "    algo = model.NN(**config)\n",
    "                   \n",
    "    train_triplets = pd.read_csv(f'../datasets/{dataset_name}/train_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "    valid_triplets = pd.read_csv(f'../datasets/{dataset_name}/valid_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "    test_triplets = pd.read_csv(f'../datasets/{dataset_name}/test_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "    \n",
    "    \n",
    "    train_data = dataset.LoaderDataset(train_triplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_triplets, concept_map, metadata) # todo : unused for the moment\n",
    "    test_data = dataset.LoaderDataset(test_triplets, concept_map,metadata) \n",
    "    # define model here\n",
    "\n",
    "    for seed in range(1) : \n",
    "        # Set the seed\n",
    "        utils.set_seed(seed)\n",
    "        \n",
    "        # train model\n",
    "        embeddings.append(algo.get_user_emb())\n",
    "\n",
    "        algo.init_model(train_data, None)\n",
    "        algo.train(train_data, valid_data)\n",
    "        \n",
    "        \n",
    "        metrics.append(algo.evaluate_test(test_data))\n",
    "        \n",
    "df = pd.DataFrame(metrics)\n",
    "print(f'lr : {lr}; num_layers : {num_layers}')\n",
    "print('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(),df['rmse'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afd8a8ea7f2a6935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T14:37:00.605903Z",
     "start_time": "2024-04-29T14:37:00.441043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr : 0.01; num_layers : 1\n",
      "rmse : 2.521 +- nan\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "print(f'lr : {lr}; num_layers : {num_layers}')\n",
    "print('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(),df['rmse'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111db5d2a674d14c",
   "metadata": {},
   "source": [
    "## DotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2c8acd9f6d0a1f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:13:32.904695Z",
     "start_time": "2024-05-29T15:13:19.882960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 13:21] train on cpu\n",
      "[INFO 13:21] -- START Training --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:01<00:00, 51.94it/s]\n",
      "100%|██████████| 76/76 [00:01<00:00, 53.45it/s]\n",
      "100%|██████████| 76/76 [00:01<00:00, 56.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 13:26] Epoch [2] \n",
      "- Losses : train=nan, valid=nan, best_valid=9223372036854775808.0000 \n",
      "- RMSE   :       -       valid=nan,  valid_4b_loss=9223372036854775808.0000,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:01<00:00, 58.39it/s]\n",
      "100%|██████████| 76/76 [00:01<00:00, 48.05it/s]\n",
      "100%|██████████| 76/76 [00:01<00:00, 47.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 13:30] Epoch [5] \n",
      "- Losses : train=nan, valid=nan, best_valid=9223372036854775808.0000 \n",
      "- RMSE   :       -       valid=nan,  valid_4b_loss=9223372036854775808.0000,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:01<00:00, 47.52it/s]\n",
      " 14%|█▍        | 11/76 [00:00<00:01, 42.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 32\u001B[0m\n\u001B[1;32m     30\u001B[0m         \u001B[38;5;66;03m# train model\u001B[39;00m\n\u001B[1;32m     31\u001B[0m         algo\u001B[38;5;241m.\u001B[39minit_model(train_data)\n\u001B[0;32m---> 32\u001B[0m         \u001B[43malgo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m         metrics\u001B[38;5;241m.\u001B[39mappend(algo\u001B[38;5;241m.\u001B[39mevaluate_test(test_data))\n\u001B[1;32m     36\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(metrics)\n",
      "File \u001B[0;32m~/Programmation/liriscat/CAT/model/abstract_model.py:87\u001B[0m, in \u001B[0;36mAbstractModel.train\u001B[0;34m(self, train_data, valid_data)\u001B[0m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ep \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     86\u001B[0m     loss_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 87\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcnt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconcepts_emb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_ids\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43muser_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[43m        \u001B[49m\u001B[43mitem_ids\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mitem_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[1;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/torch/utils/data/dataloader.py:629\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 629\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/torch/utils/data/dataloader.py:672\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    670\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    671\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 672\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    673\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    674\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:316\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[1;32m    256\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[1;32m    258\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    314\u001B[0m \u001B[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:173\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    170\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:145\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[1;32m    144\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n\u001B[0;32m--> 145\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcollate_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collections\u001B[38;5;241m.\u001B[39mabc\u001B[38;5;241m.\u001B[39mMapping):\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/liriscat/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:226\u001B[0m, in \u001B[0;36mcollate_numpy_scalar_fn\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcollate_numpy_scalar_fn\u001B[39m(batch, \u001B[38;5;241m*\u001B[39m, collate_fn_map: Optional[Dict[Union[Type, Tuple[Type, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m]], Callable]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 226\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(DBPR.utils)\n",
    "reload(DBPR.model)\n",
    "# read datasets\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i_fold in range(5):\n",
    "    config['learning_rate'] = 0.001\n",
    "    algo = model.DotProduct(**config)\n",
    "\n",
    "    train_triplets = pd.read_csv(f'../datasets/{dataset_name}/train_triples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                             \"correct\": float})\n",
    "    valid_triplets = pd.read_csv(f'../datasets/{dataset_name}/valid_triples_vert_{i_fold}.csv',\n",
    "                                 encoding='utf-8').to_records(index=False,\n",
    "                                                              column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                             \"correct\": float})\n",
    "    test_triplets = pd.read_csv(f'../datasets/{dataset_name}/test_triples_vert_{i_fold}.csv',\n",
    "                                encoding='utf-8').to_records(index=False,\n",
    "                                                             column_dtypes={'student_id': int, 'item_id': int,\n",
    "                                                                            \"correct\": float})\n",
    "\n",
    "    train_data = dataset.LoaderDataset(train_triplets, concept_map, metadata)\n",
    "    valid_data = dataset.LoaderDataset(valid_triplets, concept_map, metadata)  # todo : unused for the moment\n",
    "    test_data = dataset.LoaderDataset(test_triplets, concept_map, metadata)\n",
    "    # define model here\n",
    "\n",
    "    for seed in range(1):\n",
    "        # Set the seed\n",
    "        utils.set_seed(seed)\n",
    "\n",
    "        # train model\n",
    "        algo.init_model(train_data, None)\n",
    "        algo.train(train_data, valid_data)\n",
    "        metrics.append(algo.evaluate_test(test_data))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "print('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(), df['rmse'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7feb144409302d6",
   "metadata": {},
   "source": [
    "### Binary CDMs experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44aebfe0e4430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search\n",
    "for lr in [0.010]:\n",
    "    config['learning_rate'] = lr\n",
    "    for num_layers in [0]:\n",
    "        config['num_layers'] = num_layers\n",
    "        # read datasets\n",
    "        algo = model.GCCD(**config)\n",
    "        metrics = []\n",
    "            \n",
    "        for i_fold in range(5) : \n",
    "                           \n",
    "            train_triplets = pd.read_csv(f'../datasets/{dataset_name}/train_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "            valid_triplets = pd.read_csv(f'../datasets/{dataset_name}/valid_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "            test_triplets = pd.read_csv(f'../datasets/{dataset_name}/test_triples_vert_{i_fold}.csv', encoding='utf-8').to_records(index=False,column_dtypes={'student_id': int, 'item_id': int, \"correct\": float})\n",
    "            \n",
    "            \n",
    "            train_data = dataset.LoaderDataset(train_triplets, concept_map, metadata)\n",
    "            valid_data = dataset.LoaderDataset(valid_triplets, concept_map, metadata)\n",
    "            test_data = dataset.LoaderDataset(test_triplets, concept_map,metadata) \n",
    "            \n",
    "            \n",
    "            # Data transformation for MIRT\n",
    "            # Transform data to torch Dataloader (i.e., batchify)\n",
    "\n",
    "            \n",
    "            import torch\n",
    "            from torch.utils.data import TensorDataset, DataLoader\n",
    "            \n",
    "            def transform(x, y, z, batch_size, **params):\n",
    "                dataset = TensorDataset(\n",
    "                    torch.tensor(x, dtype=torch.int64),\n",
    "                    torch.tensor(y, dtype=torch.int64),\n",
    "                    torch.tensor(z, dtype=torch.float)\n",
    "                )\n",
    "                return DataLoader(dataset, batch_size=batch_size, **params)\n",
    "            \n",
    "            train_data, valid_data, test_data = [\n",
    "                transform(data[\"student_id\"], data[\"item_id\"], data[\"correct_binary\"],config['batch_size'] )\n",
    "                for data in [train_data, valid_data, test_data]\n",
    "            ]\n",
    "\n",
    "            # define model here\n",
    "        \n",
    "            for seed in range(1) : \n",
    "                # Set the seed\n",
    "                utils.set_seed(seed)\n",
    "                \n",
    "                # train model\n",
    "                cdm = MIRT(4164, 17747, 123)\n",
    "                cdm.train(train, valid, epoch=2)\n",
    "                cdm.save(\"mirt.params\")\n",
    "\n",
    "                algo.init_model(train_data, None)\n",
    "                algo.train(train_data, valid_data)\n",
    "                metrics.append(algo.evaluate_test(test_data))\n",
    "                \n",
    "        df = pd.DataFrame(metrics)\n",
    "        print(f'lr : {lr}; num_layers : {num_layers}')\n",
    "        print('rmse : {:.4f} +- {:.4f}'.format(df['rmse'].mean(),df['rmse'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc285ba9345122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
